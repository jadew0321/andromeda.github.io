<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jade</title>
  
  <subtitle>Notes for Machine Learning</subtitle>
  <link href="/andromeda.github.io/atom.xml" rel="self"/>
  
  <link href="https://jadew0321.github.io/andromeda.github.io/"/>
  <updated>2020-07-24T09:17:54.274Z</updated>
  <id>https://jadew0321.github.io/andromeda.github.io/</id>
  
  <author>
    <name>Jade W</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Graph Attention Networks</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/22/Graph%20Attention%20Networks/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/22/Graph%20Attention%20Networks/</id>
    <published>2020-07-22T02:30:32.000Z</published>
    <updated>2020-07-24T09:17:54.274Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文提出了一种新的基于图结构数据的神经网络结构，通过使用masked self-attentional layers 解决图卷积网络（GCN）的一些缺点。它允许(隐式地)为邻接结点集中的不同结点分配不同的权重，并且不需要任何昂贵的矩阵操作，比如反演，也不依赖于需要预先知道图形结构。本文同时解决了GCN的几个关键挑战，并使模型适用于归纳问题（Inductive）和（Transductive）问题。GAT模型在四个benchmark数据集（Cora、Citeseer、Pubmed和proteinprotein interaction）上取得了最佳结果。</p><blockquote><p>注：transductive 任务指：训练阶段与测试阶段都基于同样的图结构；inductive 任务指：训练阶段与测试阶段需要处理的图不同。通常训练阶段只是在子图（subgraph）上进行，测试阶段需要处理未知的顶点。（unseen nodes）</p></blockquote><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul><li><p>图结构化数据</p><p>卷积神经网络(CNNs)已成功应用于解决图像分类、语义分割或机器翻译等问题，其中底层数据形式具有网格状结构。这种结构能够将具有可学习参数的local filter应用到所有输入位置。然而，许多有趣的任务所涉及的数据不能以网格状结构表示，而是位于一个不规则的域中，如三维网格、社交网络、电信网络、生物网络或大脑连接体。这些数据通常可以以图的形式表示。</p></li><li><p>相关前人工作</p><ol><li><p>使用递归神经网络处理用有向无环图表示的图结构数据。[1,2]</p></li><li><p>使用图神经网络[3,4]直接处理更多类型的图（如循环、有向、无向图），可看作是递归神经网络的推广。它用神经网络基于节点当前的状态来产生一个输出，不断迭代此过程来更新节点的状态，直至达到平衡。Li[5]等人采用并改进了这个想法，提出在传播步骤中使用门控循环单元[6]。</p></li></ol></li><li><p>卷积的推广</p><p>然而，人们对将卷积推广到图域越来越感兴趣。这方面的进展通常分为谱方法和非谱方法。</p><ol><li><p>谱方法（基于图的谱表示）</p><ul><li><p>进展：计算图的拉普拉斯特征分解在频域里定义卷积操作；[7]</p><p>缺点：计算复杂，并且不具有空域局部滤波器特性。</p></li><li><p>进展：进行具有平滑系数的谱滤波器的参数化；[8]</p><p>缺点：计算依然复杂</p></li><li><p>进展：通过图拉普拉斯算子的切比雪夫展开式去近似滤波器，省去了特征根分解的步骤，并具有空域局部滤波器特性；[9]</p></li><li><p>进展：通过限制过滤器在每个节点周围的一步邻域内操作，简化了图卷积网络的模型；[10]</p></li></ul></li></ol></li></ul><blockquote><p> 然而，在所有上述谱方法中，学习到的滤波器依赖于拉普拉斯特征基，而拉普拉斯特征基依赖于图结构。因此，针对特定结构训练的模型不能直接应用于具有不同结构的图。</p></blockquote><ol><li><p>非谱方法（直接在图上定义卷积，对一组空间近邻节点进行操作）</p><ul><li>挑战：如何定义一个操作能够处理不同大小的邻域，并保持CNN的权重共享性质。</li><li>进展：mixture model CNNs (MoNet)[11]、GraphSAGE[12]等。</li></ul></li></ol><ul><li><p>注意力机制</p><p>优势之一是它们允许处理不同大小的输入，通过关注输入中最相关的部分来做出决定。self-attention / intra-attention使用注意机制来计算单个序列的表示，不仅能提升RNN和CNN的性能，而且足以用于构建一个更强大的模型，因此本文提出了GAT，具有以下优势：</p><ol><li>操作效率高，在跨节点对中可并行计算;</li><li>通过对相邻节点指定任意权值，可应用于不同度的图节点;</li><li>该模型直接适用于归纳学习问题，包括讲模型推广到完全不可见图的任务。</li></ol></li></ul><h1 id="GAT-Architecture"><a href="#GAT-Architecture" class="headerlink" title="GAT Architecture"></a>GAT Architecture</h1><h3 id="Graph-Attentional-Layer"><a href="#Graph-Attentional-Layer" class="headerlink" title="Graph Attentional Layer"></a>Graph Attentional Layer</h3><ul><li><p>输入输出</p><p>GA层的输入是一组节点特征，记为 $\mathbf{h}=\left\{\vec{h}_{1}, \vec{h}_{2}, \ldots, \vec{h}_{N}\right\}, \vec{h}_{i} \in \mathbb{R}^{F}$ ，其中 $N$ 是节点的个数，$F$ 是每个节点的特征数。</p><p>GA层的输出是一组新的节点特征，记为 $\mathbf{h}^{\prime}=\left\{\vec{h}_{1}^{\prime}, \vec{h}_{2}^{\prime}, \ldots, \vec{h}_{N}^{\prime}\right\}, \vec{h}_{i}^{\prime} \in \mathbb{R}^{F^{\prime}}$，其中节点个数$N$不变，每个节点的特征数可变化为 $F^{\prime}$。</p></li><li><p>共享线性变换</p><p>为了将输入特征转换为高维特征（增维）以获得足够的表达能力，每个节点将经过一个共享的线性变换，该模块的参数用权重矩阵 $\mathbf{W} \in \mathbb{R}^{F^{\prime} \times F}$来表示，对某个节点做线性变换可表示为 $\mathbf{W} \vec{h}_{i} \in \mathbb{R}^{F^{\prime} }$。这是一种常见的特征增强（feature augment）方法。</p></li><li><p>self-attention 机制</p><p>同样是在每个节点间共享self-attention 机制：$\mathbb{R}^{F^{\prime}} \times \mathbb{R}^{F^{\prime}} \rightarrow \mathbb{R}$，可计算节点 $i$ 和 $j$ 之间的attention 系数如下：</p><script type="math/tex; mode=display">e_{i j}=a\left(\mathbf{W} \vec{h}_{i}, \mathbf{W} \vec{h}_{j}\right)</script><p>该系数表示了节点 $i$ 的特征对节点 $j$ 的重要性。注意机制 $a$ 是一个单层前馈神经网络，用一个权重向量来表示：$\overrightarrow{\mathbf{a}} \in \mathbb{R}^{2 F^{\prime}}$，它把拼接后的长度为2F的高维特征映射到一个实属上，作为注意力系数。</p><p>attention 机制分为以下两种：</p><ol><li>Global graph attention：允许每个节点参与其他任意节点的注意力机制，它忽略了所有的图结构信息。</li><li>Masked graph attention：只允许邻接节点参与当前节点的注意力机制中，进而引入了图的结构信息。</li></ol><p>本文采用Masked graph attention，并且邻接节点是一阶邻接节点（包括节点本身）。</p><p>为了使不同节点间的注意力系数易于比较，使用softmax函数对所有对于节点 $i$ 的注意力系数进行归一化：</p><script type="math/tex; mode=display">\alpha_{i j}=\operatorname{softmax}_{j}\left(e_{i j}\right)=\frac{\exp \left(e_{i j}\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(e_{i k}\right)}</script></li></ul><p>上述注意力机制，采用共享权重线性变换、Masked self attention 和 LeakyReLU非线性（negative input slope α = 0.2）归一化后的计算公式如下：</p><script type="math/tex; mode=display">\alpha_{i j}=\frac{\exp \left(\text { LeakyReLU }\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\text { Leaky ReLU }\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{k}\right]\right)\right)}</script><p>其中 T表示转置，||表示拼接。</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_11-05-51.png?raw=true" alt="Snipaste_2020-07-24_11-05-51" style="zoom: 67%;"></p><ul><li><p>节点特征更新</p><p>在得到归一化的注意力系数之后，可以通过对邻接节点特征的线性组合经过一个非线性激活函数来更新节点自身的特征作为输出：</p><script type="math/tex; mode=display">\vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \vec{h}_{j}\right)</script></li></ul><h3 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h3><p>为了稳定self-attention的学习过程，本文使用多头注意力机制。具体地，使$K$ 个独立注意力机制根据上式进行变换，得到更新的节点输出特征，然后将$K$ 个特征拼接（concat），得到如下输出特征：</p><script type="math/tex; mode=display">\vec{h}_{i}^{\prime}=\prod_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)</script><p>由于加入了multi-head attention，GA层最终返回的输出将包含每个节点的$KF’$个特征 (而不是$F’$)。</p><p>如果 $\vec{h}_{i}^{\prime}$ 是网络的最后一层输出，可以选择对K个独立的注意力机制进行求平均（avg），然后经过非线性激活函数得到最终的输出：</p><script type="math/tex; mode=display">\vec{h}_{i}^{\prime}=\sigma\left(\frac{1}{K} \sum_{k=1}^{K} \sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)</script><p>Multi-head attention mechanism 的示意图如下所示：</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_14-43-23.png?raw=true" alt="Snipaste_2020-07-24_14-43-23" style="zoom: 67%;"></p><h1 id="Comparisons-to-Related-Work"><a href="#Comparisons-to-Related-Work" class="headerlink" title="Comparisons to Related Work"></a>Comparisons to Related Work</h1><p>GA层直接解决了用神经网络处理图结构数据方法中存在的几个问题：</p><ol><li>计算上高效：自注意力层的操作可以并行化到所有的边，输出特征的计算也可以并行化到所有的节点，multi-head attention 中每一头的计算也可以并行化。 </li><li>与GCNs不同的是，GAT模型允许(隐式地)为同一邻接节点分配不同的重要性，从而实现了模型容量的飞跃；此外，分析学习到的注意力系数可能会在可解释性方面带来一些好处。</li><li>注意力机制以一种共享的方式应用于图中的所有边，因此它不依赖于预先访问全局图结构或其所有节点的(特征)(这是许多先前技术的限制)。<ul><li>不要求图是无向的，如果 $j$ -&gt;$i$ 不存在，我们只需省去计算$\alpha_{i j}$即可。</li><li>使得模型能够处理inductive任务，能够在训练中完全看不到的图形上评估模型。</li></ul></li><li>无需对节点的重要性进行预先排序</li><li>GAT模型是MoNet的一个特例，但与MoNet相比，GAT模型使用节点特征进行相似性计算，而不是节点的结构属性(这需要预先知道图形结构)。</li></ol><p>文章还提出了一个利用稀疏矩阵操作版本的GAT层，降低存储复杂度，并允许在更大的图数据集上执行GAT模型。但由于使用的是rank-2  tensors，它限制了GAT的批处理能力，尤其是对具有多个不同图结构的数据集来说。这也是未来的一项研究工作。  </p><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_15-23-08.png?raw=true" alt="Snipaste_2020-07-24_15-23-08"></p><ul><li><p>Transductive Learning：</p><p>Cora、Citeseer、Pubmed是三个无向固定图结构的数据集，适用于Transductive Learning。每个节点都有一个类别标签，节点特征是词向量表示。每一类用20个节点进行训练，500个节点进行验证，1000个节点进行测试。</p></li><li><p>Inductive Learning：</p><p>protein-protein interaction (PPI) 数据集包含不同人类组织对应的不同图结构，适用于Inductive Learning。用其中20个图进行训练，2个图进行验证，2个图进行测试。测试图在训练过程中是完全没有被观察到过的。</p></li></ul><h3 id="State-of-the-art-Methods"><a href="#State-of-the-art-Methods" class="headerlink" title="State-of-the-art Methods"></a>State-of-the-art Methods</h3><ul><li><p>Transductive Learning：</p><p>label propagation (LP)、semi-supervised embedding (SemiEmb)、manifold regularization (ManiReg)、skip-gram based graph embeddings (Deep- Walk)、iterative classification algorithm (ICA)、Planetoid、GCNs、graph convolutional models utilising higher-order Chebyshev filters、MoNet model</p></li><li><p>Inductive Learning：</p><p>GraphSAGE-GCN、GraphSAGE-mean、GraphSAGE-LSTM、GraphSAGE-pool</p></li><li><p>另外，对于这两个任务，还提供了每个节点共享多层感知器(MLP)分类器的性能(它完全不包含图结构)。</p></li></ul><h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><ul><li><p>Transductive Learning：</p><p>对于前两个数据集，建立两层GAT模型，第一层$K=8$, $F’=8$，输出特征数为64，经过exponential linear unit (ELU) 非线性函数；第二层用于分类，$K=1$，采用softmax激活函数。为了解决训练集较小的问题，正则化在模型中得到了广泛的应用。在训练中，我们应用L2正则化（$lamda=0.0005$），dropout（$p=0.6$）。</p><p>对于第三个数据集，改变第一层$K=8$，L2正则化（$lamda=0.001$），其他结构和参数保持不变。</p></li><li><p>Inductive Learning：</p><p>采用三层GAT模型，前两层$K=4$，$F’=256$，输出特征为1024，经过ELU 非线性函数；最后一层用于分类，$K=6$，$F’=121$，对输出特征进行平均并经过一个logistic sigmoid 激活函数。由于训练集充足，未采用L2正则化和dropout，但使用了skip connections挑过了中间的注意力层。</p><p>所有模型采用Glorot初始化，采用Adam SGD optimizer（Pubmed数据集学习率取0.01，其余数据集学习率为0.005），最小化交叉熵损失，使用早期停止策略。</p></li></ul><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>实验结果如下表所示：</p><p>​        <img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_16-42-04.png?raw=true" alt="Snipaste_2020-07-24_16-42-04"></p><p>​        <img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_16-42-16.png?raw=true" alt="Snipaste_2020-07-24_16-42-16"></p><ol><li>跟GCNs相比，GAT模型在Cora和Citeseer数据集上精度分别提高了1.5%和1.6%，这表明对邻接节点分配不同的注意力系数是有益的。</li><li>跟GraphSAGE相比，GAT在PPI数据集上精度提高了20.5%，说明了GAT模型在inductive任务上的潜力，以及对不同邻接节点分配不同注意力系数的有效性。</li></ol><p>GAT模型在Cora数据集上的分类结果可视化如下：</p><p>​        <img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_17-08-14.png?raw=true" alt="Snipaste_2020-07-24_17-08-14"></p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>本文提出了图注意力网络(GATs)，这是一种新型的利用masked自注意力层的卷积式神经网络，它能够处理图结构的数据，具有计算简洁、允许不同权重的邻接结点、不依赖于整个图结构等优势，可以处理谱方法的一诸多缺陷，在各数据集上获得了最佳的性能。</p><h1 id="Future-Works"><a href="#Future-Works" class="headerlink" title="Future Works"></a>Future Works</h1><p>有几个潜在的可改进和扩展GATs的未来工作，如克服前述只能处理一个批次数据的实际问题，使得模型能够处理更大的批次数据。另外一个特别有趣的研究方向是利用注意力机制对模型的可解释性进行深入分析。最后，扩展模型以包含边的特征(可能表示节点之间的关系)将允许我们处理更多种问题。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><blockquote><ol><li>Paolo Frasconi, Marco Gori, and Alessandro Sperduti. A general framework for adaptive processing<br>of data structures. IEEE transactions on Neural Networks, 9(5):768–786, 1998.</li><li>A. Sperduti and A. Starita. Supervised neural networks for the classification of structures. Trans.<br>Neur. Netw., 8(3):714–735, May 1997. ISSN 1045-9227. doi: 10.1109/72.572108.</li><li>Marco Gori, Gabriele Monfardini, and Franco Scarselli. A new model for learning in graph domains. In IEEE International Joint Conference on Neural Networks, pp. 729734, 2005.</li><li>Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini.<br>The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61–80, 2009.</li><li>Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural<br>networks. International Conference on Learning Representations (ICLR), 2016.</li><li>Kyunghyun Cho, Bart Van Merri¨enboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.</li><li>Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally<br>connected networks on graphs. International Conference on Learning Representations (ICLR),<br>2014.</li><li>Mikael Henaff, Joan Bruna, and Yann LeCun. Deep convolutional networks on graph-structured<br>data. arXiv preprint arXiv:1506.05163, 2015.</li><li>Micha¨el Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems, pp. 3844–3852, 2016.</li><li>Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. International Conference on Learning Representations (ICLR), 2017.</li><li>Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodol`a, Jan Svoboda, and Michael M Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. arXiv preprint arXiv:1611.08402, 2016.</li><li>William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large<br>graphs. Neural Information Processing Systems (NIPS), 2017.</li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;本文提出了一种新的基于图结构数据的神经网络结构，通过使用masked self-attent
      
    
    </summary>
    
    
      <category term="GNN" scheme="https://jadew0321.github.io/andromeda.github.io/categories/GNN/"/>
    
    
      <category term="paper" scheme="https://jadew0321.github.io/andromeda.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>How to create your personal homepage</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/10/How-to-create-your-personal-homepage/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/10/How-to-create-your-personal-homepage/</id>
    <published>2020-07-10T02:04:59.000Z</published>
    <updated>2020-07-11T03:32:58.630Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>碎碎念：好多之前的博客也是没坚持多久就不接着写下去了，过几天把比较有价值的搬运过来。开始Github Pages也是因为一个很喜欢的师妹，给我看了她自己的网站，简直！酷炫！太符合她的人设啦~ 新鲜感驱使我在一大堆bug里乘风破浪，搭了这个小窝，希望这次可以坚持地久一些。</p></blockquote><h1 id="安装Node"><a href="#安装Node" class="headerlink" title="安装Node"></a>安装Node</h1><ul><li><p>在<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Node</a>官网下载对应版本的软件，按默认方式一路安装直至成功。</p></li><li><p>验证：进入cmd，输入以下代码，如果显示Git版本信息说明安装成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure></li></ul><h1 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h1><ul><li><p>在<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">Git官网</a>下载对应版本的软件，按默认方式一路安装直至成功。</p></li><li><p>验证：进入cmd，输入以下代码，如果显示Git版本信息说明安装成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git --version</span><br></pre></td></tr></table></figure></li><li><p>这时候对任意一个文件夹点右键，会有多出来两个选项“Git GUI Here”和“Git Bash Here”</p></li></ul><h1 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h1><ul><li><p>选择一个存放blog文件的路径，新建文件夹，重命名为你想要的名字，我就用了myblog命名文件夹，鼠标放在myblog文件夹上点右键，选择Git Bash Here（之后很多操作都会从Git Bash Here开始）。依次输入以下命令，安装完输下一个。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p>然后就静静等待他叭啦叭啦装完。</p></li></ul><h1 id="初始化Hexo"><a href="#初始化Hexo" class="headerlink" title="初始化Hexo"></a>初始化Hexo</h1><ul><li><p>执行以下初始化命令，会自动在你命名的文件夹（这里是blog）中新建所需要的文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init blog</span><br><span class="line">cd blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><p>顺利的话，运行下面的命令，在浏览器中输入<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 就可以看到网页的预览效果了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure></li></ul><h1 id="建立Github-Pages"><a href="#建立Github-Pages" class="headerlink" title="建立Github Pages"></a>建立Github Pages</h1><ul><li><p>注册Github就不多说啦，注册完新建repositories，Github只能用一个同名仓库的代码托管一个站点，注意一下就好。</p></li><li><p>repository name 必须是以 github.io结尾，比如我的 andromeda.github.io，硬性规定遵守即可。</p><p>（我这里因为新建过同名仓库了，所以显示不能用这个名字）</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/1.jpg?raw=true" alt="1" style="zoom:50%;"></p></li><li><p>新建仓库完成后，进入该仓库的Settings，查看和熟悉一下，往下拉有个Github Pages，下面这个画横线的站点就是我们创建的个人网页地址，放收藏夹哈之后会一直用到的。选择master branch，如果这个选择是灰的，就先点下一个按键，选一个主题之后就自动master branch啦~</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/3.jpg?raw=true" alt="3"></p><p>先看一眼我踏过千山万水、填过千沟万壑之后的blog成品图</p><p>好搞笑哦，能看到这篇博客的应该也能看到主页吧！多此一举多此一举。go on~</p></li></ul><h1 id="配置SSHkey"><a href="#配置SSHkey" class="headerlink" title="配置SSHkey"></a>配置SSHkey</h1><ul><li><p>要使用git工具首先要配置以下SSH Key，为部署本地博客到Github做准备。在第一次新建的文件夹里面 Git Bash Here 输入以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ~&#x2F;.ssh</span><br></pre></td></tr></table></figure><p>如果没有报错或者提示什么的就说明是以前生成过的，可以直接使用以下命令查看本机SSH Key</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~&#x2F;.ssh&#x2F;id_rsa.pub</span><br></pre></td></tr></table></figure><p>如果之前没有创建，就执行以下命令配置本地账户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name</span><br><span class="line">git config --global user.email</span><br><span class="line">ssh-keygen -t rsa -C user.email</span><br></pre></td></tr></table></figure><p>按照提示敲三次回车，就可以生成啦。再通过cat ~/.ssh/id_rsa.pub查看key就可以了。</p><p>然后需要确认并添加主机到本机SSH可信列表，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>如果返回 Hi XXX！……等一系列话，就说明你添加成功了。接下来去Github网页版右上角点+号，找到Settings-SSH and GPG keys-New SSH key，复制刚刚生成的SSH Key并生成就OK了。命令行窗口可以不用关掉，之后还要来用的！</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/5.png?raw=true" alt="5"></p></li></ul><h1 id="连接Github与本地blog文件"><a href="#连接Github与本地blog文件" class="headerlink" title="连接Github与本地blog文件"></a>连接Github与本地blog文件</h1><ul><li><p>打开博客根目录下的_config.yml 配置文件，拉到最后，在deployment段落中填上以下信息：</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/4.png?raw=true" alt="4"></p><p>第一个大坑来了！！！除了网上各大教程都说了的，要在冒号后面加一个空格之外！！！千万千万千万不要修改type\repository\branch前面的缩进！一定是要在原始的格式上，在冒号后空一格填上你对应的信息……可能大家也没有我这么手贱，去强行缩进和改动，以至于后面一直一直部署不了。</p></li><li><p>修改完之后就可以继续在命令行窗口输入下面的generate代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure></li><li><p>稍等几十秒，最多几分钟，就可以在浏览器上输入你自己的站点，然后看到最原始的博客界面啦！</p></li></ul><h1 id="好看最重要！"><a href="#好看最重要！" class="headerlink" title="好看最重要！"></a>好看最重要！</h1><p>接下来一定是去<a href="https://hexo.io/themes/" target="_blank" rel="noopener">hexo模板官网</a>找一个好看的模板了呀！个人比较喜欢简洁大气的风格，用的是diaspora。之前拍的写真可以派上用场了喜喜。</p><p>不同的模板有不同的安装和配置方法，这里就不详细展开啦，大家自行百度 ”xxx模板 hexo配置“ 基本都可以找到教程，换上自己喜欢的背景图片和logo，一个专属的网页就生成啦！</p><p>具体的写作和数学公式以及图片显示等等细节，可以参看这个<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo中文文档</a>。</p><p><em>最后提醒自己一百遍：坚持坚持坚持！！！</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;碎碎念：好多之前的博客也是没坚持多久就不接着写下去了，过几天把比较有价值的搬运过来。开始Github Pages也是因为一个很喜欢的师妹，给我看了她自己的网站，简直！酷炫！太符合她的人设啦~ 新鲜感驱使我在一大堆bug里乘风破浪，搭了这个小窝，希望
      
    
    </summary>
    
    
      <category term="Hexo" scheme="https://jadew0321.github.io/andromeda.github.io/categories/Hexo/"/>
    
    
      <category term="technique" scheme="https://jadew0321.github.io/andromeda.github.io/tags/technique/"/>
    
  </entry>
  
  <entry>
    <title>Handling Variable-Dimensional Time Series with Graph Neural Networks</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/</id>
    <published>2020-07-09T02:10:20.000Z</published>
    <updated>2020-07-13T02:20:09.069Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-MOTIVATION"><a href="#1-MOTIVATION" class="headerlink" title="1-MOTIVATION"></a>1-MOTIVATION</h1><ul><li><p>物联网(IoT)技术的一些应用涉及<u>从多个传感器捕获数据</u>，从而产生多传感器时间序列。</p></li><li><p>现有的基于神经网络（NN）的多变量时间序列建模方法<u>假设传感器的输入维数（即传感器的数量）是固定的。</u></p></li><li><p>在实际应用中，例如手机、穿戴设备、工业设备等，这些<u>相同设备的不同实例安装的传感器组合通常是不同的</u>，因此无论下游任务是预测还是分类，模型在设计时就<u>需要考虑不同(可变)的输入维度</u>，以构造一个针对某一设备来说<u>较为通用的模型架构</u>。</p></li></ul><h1 id="2-INTRODUCTION"><a href="#2-INTRODUCTION" class="headerlink" title="2-INTRODUCTION"></a>2-INTRODUCTION</h1><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>由于IoT的快速发展，设备范围的不断扩大，多传感器时间序列数据无处不在并且快速增长。深度学习方法已经成功地应用于多元时间序列预测、分类、异常检测和剩余有用寿命估计。</p><h3 id="假设与矛盾"><a href="#假设与矛盾" class="headerlink" title="假设与矛盾"></a>假设与矛盾</h3><p>大多数现有的对多变量时间序列数据建模的方法假设固定维的时间序列作为输入，<u>这在许多实际情况下，这种假设可能并不成立</u>。例如，在学习活动识别模型时，由于穿戴设备实例的不同，不同人的时间序列可能<u>涉及到不同数量的可用传感器</u>(如加速度计、陀螺仪、磁力仪)。类似地，设备运行状况监控模型也需要处理来自不同实例设备的数据，这些<u>实例上安装了不同的传感器</u>(比如温度、振动和压力)。</p><h3 id="针对场景"><a href="#针对场景" class="headerlink" title="针对场景"></a>针对场景</h3><p>在这项工作中，作者考虑了<u>由同一底层动力系统的不同实例</u>(例如在活动识别中的人)生成多个<u>不同传感器组合的多元时间序列分析问题</u>。即网络的输入维度是不确定的，（但不超过某个最大上限）。</p><h3 id="方法优势"><a href="#方法优势" class="headerlink" title="方法优势"></a>方法优势</h3><p>提出的模型在zero-shot （测试集中可用传感器的组合与训练集中的组合都不相同）和fine-tuning （训练集中包含有少量与测试实例相同组合的样本可用于微调）两个设定实验下性能优于普通NN模型，并且通过ablation study验证了模型各个组成成分的有效性。</p><h1 id="3-RELATED-WORKS"><a href="#3-RELATED-WORKS" class="headerlink" title="3-RELATED WORKS"></a>3-RELATED WORKS</h1><h6 id="把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。"><a href="#把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。" class="headerlink" title="把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。"></a>把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。</h6><ul><li>但是随着测试实例中传感器丢失百分比的增加，该方法的性能会迅速下降。</li></ul><h6 id="仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。"><a href="#仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。" class="headerlink" title="仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。"></a>仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。</h6><ul><li>由于它们依赖于时间序列中每个维度至少有一个可用值的情况，因此不适用于整条时间序列缺失的问题设置。</li></ul><h6 id="针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。"><a href="#针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。" class="headerlink" title="针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。"></a>针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。</h6><ul><li>当可能组合的数量呈指数级增长时，网络扩展困难; </li><li>假设每一种组合都有足够的训练数据可用; </li><li>且不同模型训练时不保留任何跨组合的知识。</li></ul><p><em>以上相关方法都有一定的缺陷，因此作者在GNN、transfer-learning、meta-learning的启发下，提出了一种新的神经网络结构，适用于zero-shot 和fine-tuning迁移学习，能够实现在测试时对多变量时间序列进行鲁棒的推理，且这些多变量时间序列中的有效维度（即可用的传感器组合）是未知的。</em></p><h1 id="4-PROBLEM-DEFINITION"><a href="#4-PROBLEM-DEFINITION" class="headerlink" title="4-PROBLEM DEFINITION"></a>4-PROBLEM DEFINITION</h1><p>对本问题场景进行数学上的描述，对于符号达成以下共识：</p><ul><li>考虑一个训练集$\mathcal{D}=\left\{\left(\mathbf{x}_{i}, y_{i}\right)\right\}_{i=1}^{N}$ ，具有$N$个多变量时间序列 $\mathbf{x}_{i} \in \mathcal{X}$ 和对应的标签 $y_i \in \mathcal{Y}$。</li><li>每个时间序列 $\mathbf{x}_{i}=\left\{\mathbf{x}_{i}^{t}\right\}_{t=1}^{T_{i}}$的长度都为 $T_i\in\mathcal{T}$。</li><li>$\mathcal{S}$表示包含所有传感器的集合，共$d$维（即变量最大维度为$d$）；$\mathcal{S}_i \subseteq \mathcal{S}$表示不同的传感器组合，其下标 $i$与 $\mathbf{x}_{i}$ 中的下标对应，表示当前组合包含的可用传感器共$d_i$维，$1 \leq d_{i} \leq d$。</li><li>对于某个时刻$t$来说，$\mathbf{x}_{i}^{t}$ 是 一个 $d_i$ 维的向量，即 $\mathbf{x}_{i}^{t} \in \mathbb{R}^{d_{i}}$。</li><li>下游任务的目标是，学习到 $\mathcal{X}$ 与 $\mathcal{Y}$ 之间的映射关系：$f: \mathcal{X} \rightarrow \mathcal{Y}$。</li></ul><h1 id="5-APPROACH"><a href="#5-APPROACH" class="headerlink" title="5-APPROACH"></a>5-APPROACH</h1><p>作者提出一个新的基于GNN的时间序列分析模型，利用神经网络架构（GRU，当然LSTM也可）与两个全新的模块：</p><ul><li><p>core dynamics module——用于对数据的时序特性进行建模；</p></li><li><p>conditioning module——基于不同的传感器组合，利用GNN学习各可用传感器之间的信息聚合关系，并生产一个“conditioning vector”作为附加输入传递至core dynamic module，对时序特性的建模进行定制化调整。</p></li></ul><p>模型总体架构示意图如下所示：</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/1.jpg?raw=true" alt="1"></p><h3 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h3><ul><li><p>Details</p><p>首先确定最大变量维度d，所有变量组合的维度$1 \leq d{i} \leq d$。如左下角的Input Time Series(x) 所示，对第二维缺失传感器数值的维度进行mean-imputed，即该传感器在其他实例中可用时的平均值，预处理后的多变量时序数据$\mathbf{x}{i}$中每个时刻的输入都是一个d维向量。</p><p><em>这个操作实质上是为了能把等长维度的数据喂给GRU网络作为输入。</em></p></li></ul><h3 id="Conditioning-Module"><a href="#Conditioning-Module" class="headerlink" title="Conditioning Module"></a>Conditioning Module</h3><ul><li><p>Details</p><ul><li><p>在图表示学习的启发下，将每一个可用的传感器看作一个结点（vertices）。两个结点之间的关系定义为边（edges）。对应于包含全部传感器的组合$\mathcal{S}$，考虑用图$\mathcal{G}(\mathcal{V}, \mathcal{E})$来表示，每个$s\in\mathcal{S}$ 对应一个结点$v_s\in \mathcal{V}$，每个结点$v_s$的邻节点用 <script type="math/tex">\mathcal{N}_{\mathcal{G}}\left(v_{s}\right)</script> 表示。</p></li><li><p>每个传感器 $s \in \mathcal{S}$ 与一个可学习的embeding vector（嵌入向量） $v_s\in \mathbb{R}^{d_{s}}$ 相关联。</p></li><li><p>对于一个特定的多个传感器的组合$\mathcal{S}_i$，可用的传感器对应的结点被激活，图中每两个active结点之间连成的边也被为激活（fullly-connected）。因此，就如结构图上GNN框中的三个彩色结点所示，这三个结点以及它们两两之间的边都是激活的。</p></li><li><p>对于不同的组合都有一个确定的图结构，基于图结构我们构造结点更新网络及边更新网络：</p><ul><li><p>node-specific feed-forward network（结点前馈网络）&amp; edge-specific feed-forward network（边前馈网络）</p><p>结点的更新体现了相邻结点对当前结点的聚合作用，具体的，对于任意一个active node$v_k$，对应的结点向量$\mathbf{v}_{k}$的更新公式如下：</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{v}_{k l} &=f_{e}\left(\left[\mathbf{v}_{k}, \mathbf{v}_{l}\right] ; \boldsymbol{\theta}_{e}\right), \quad \forall v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right) \\\tilde{\mathbf{v}}_{k} &=f_{n}\left(\left[\mathbf{v}_{k}, \sum_{\forall l} \mathbf{v}_{k l}\right] ; \boldsymbol{\theta}_{n}\right)\end{aligned}</script><p>其中，$\mathbf{V}_{k l}$表示所有与$v_k$相连的结点$v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right)$对$v_k$产生的作用。</p><p>$\tilde{\mathbf{V}}_{k}$表示$v_k$在聚合了所有$\mathbf{V}_{k l}$对她的影响之后，对自身结点的一个更新。</p><p>$\theta _e$和$\theta _n$分别为$f_e$和$f_n$的可学习参数，简单来说，$f_e$将邻结点信息传递到待更新结点，$f_n$利用邻结点的聚合信息更新相应结点。</p><p><em>另外，$fn$和$fe$在图中所有的结点和边上共享权重系数，也就是说这两个网络训练的不是特定点之间或特定边上的更新方式，而是整个图通用的更新方式。</em></p><p>最后根据更新后的各结点向量得到一个 conditioning vector <script type="math/tex">\mathbf{v}_{\mathcal{S}_{i}} \in \mathbb{R}^{d_{s}}</script></p><script type="math/tex; mode=display">\mathbf{v}_{\mathcal{S}_{i}}=\max \left(\left\{\tilde{\mathbf{v}}_{k}\right\}_{v_{k} \in \mathcal{V}_{i}}\right)</script><p>注意，最大化操作原理同卷积网络中的池化操作，也可用平均值代替，相当于卷积网络中的平均池化，但经过作者实验，发现最大池化效果要优于平均池化，因此采用对$\tilde{\mathbf{V}}_{k}$的每一个维度取最大值操作，得到最终的conditioning vector。</p></li><li><p><em>本模块采用GNN的优势在于，它学习到的是一个通用的所有结点之间的聚合关系，因此不仅可以处理在训练中出现过的组合，在测试时，可以处理训练集中见过的变量组合之外的unseen组合，从而提高了对组合处理的泛化能力，这也是可以应对zero-shot的本质原因。</em></p></li></ul></li></ul></li></ul><h3 id="Core-Dynamics-Module"><a href="#Core-Dynamics-Module" class="headerlink" title="Core Dynamics Module"></a>Core Dynamics Module</h3><ul><li><p>Details</p><ul><li>Core Dynamics Module 包含一个gated RNN模型，文中采用GRU，当然也可以用LSTM等。</li><li>输入时固定维度的多变量时序数据（由于在数据预处理中，我们将缺失的变量用常量进行了填补，并记填补后的输入为$\tilde{\mathbf{x}}_{i}$）。</li><li>与普通的模型输入不同的是，在本模块中，需要把时序数据$\tilde{\mathbf{x}}_{i}$和上面模块中得到的conditioning vector 拼接起来（维度扩展）一起输入GRU进行训练，并与上一时刻的特征向量一起，往下一个时刻进行信息传输，具体公式为：</li></ul><script type="math/tex; mode=display">\mathbf{z}_{i}^{t}=G R U\left(\left[\tilde{\mathbf{x}}_{i}^{t}, \mathbf{v}_{\mathcal{S}_{i}}\right], \mathbf{z}_{i}^{t-1} ; \boldsymbol{\theta}_{G R U}\right), \quad t: 1, \ldots, T_{i}</script><ul><li>在最后一个时刻，得到模型输出的特征向量$\mathbf{z}_{i}^{T_i}$，预测的输出根据不同的下游任务进行构造和确定：<script type="math/tex; mode=display">\hat{y}_{i}=f_{o}\left(\mathbf{z}_{i}^{T_{i}} ; \boldsymbol{\theta}_{o}\right)</script>附上LSTM和GRU的结构图作为参考：</li></ul></li></ul><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/2.png?raw=true" alt="2"></p><h3 id="Training-Rules"><a href="#Training-Rules" class="headerlink" title="Training Rules"></a>Training Rules</h3><ul><li>整个模型通过随机梯度下降（SGD）以end-to-end的形式进行整体的训练。</li><li><p>损失函数：</p><ul><li>分类：<script type="math/tex">\mathcal{L}_{c}=-\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i}^{k} \log \left(\hat{y}_{i}^{k}\right)</script></li><li>预测：<script type="math/tex">\mathcal{L}_{r}=\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2}</script></li></ul></li><li><p><em>注意：该模型参数学习的方式为mini-batch SGD，是在每个mini-batch内输入具有相同变量组合的时间序列进行训练，而整个batch包含多种不同的变量组合。</em></p></li></ul><h1 id="6-EXPERIMENT"><a href="#6-EXPERIMENT" class="headerlink" title="6-EXPERIMENT"></a>6-EXPERIMENT</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><ul><li>DSADS</li><li>HAR</li><li>Turbofan</li></ul><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/3.jpg?raw=true" alt="3"></p><h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><ul><li>Zero-shot setting：把一部分变量组合包含的数据作为训练数据，除训练集外剩下所有unseen的组合作为测试数据，直接使用训练好的网络进行推理。</li><li>Fine-tuning setting：把一部分变量组合包含的数据作为训练数据，使用除训练集外的一部分与测试集相同变量组合的带标记数据来微调网络参数，用剩下的测试数据进行测试。</li><li>$f_{t r}$和$f_{t e}$表示训练和测试过程中每个时间序列不可用传感器的比例，把训练时的比例记为$f_{t r}=\{0.25,0.4\}$，测试时的比例记为$f_{t e}=\{0.1,0.25,0.4,0.5\}$ </li><li>对于所有数据集，40%用于训练，10%用于验证，10%用于微调(在zero-shot情况下忽略)，其余40%用于测试。</li><li>评价指标：分别使用分类错误率和均方根误差(RMSE)作为分类和回归任务的性能指标。</li></ul><h3 id="Hyperparameters-Used"><a href="#Hyperparameters-Used" class="headerlink" title="Hyperparameters Used"></a>Hyperparameters Used</h3><ul><li>core dynamics module 由三层GRU构成，每层GRU各有128个单元，每个结点的嵌入向量维度为d/2。</li><li>mini-batch在训练时和fine-tuning时的大小分别为64和32，所有前馈层之后都有0.2的dropout用于正则化，训练时采用最大150 epoch，微调时采用最大50 epoch。</li><li>使用无动量的vanilla SGD以5e-4的学习率来更新传感器嵌入向量，用Adam以1e-4的学习率来更新的其他层的学习速率。（由于active 结点在每一个mini-batch中都会随着可用传感器组合的变化而变化，我们发现使用vanilla SGD来更新传感器向量是有用的，然而如果我们加入动量，非active结点的向量也会得到更新；另一方面，在所有变量组合和mini-batch共享的GNN和核心模块，都受益于momentum，因此Adam用于更新它们的参数。)</li></ul><h3 id="Baselines-Considered"><a href="#Baselines-Considered" class="headerlink" title="Baselines Considered"></a>Baselines Considered</h3><ul><li>GRU-CM (GRU with GNNbased conditioning module)：文章提出的模型</li><li>GRU：在缺失传感器中填充均值，相当于GRU-CM模型去掉了conditioning module，只有时序模块，因此不会给GRU提供额外的条件向量信号。</li><li>GRU-A（GRU with All Sensors Available）：该模型对于所有的训练和测试实例，可使用所有的传感器的数值，（即无传感器缺失），训练超参数与GRU-CM相同，旨在找出模型精度的一个上届。</li><li>GRU-SE（GRU with Maxpool over Sensor Embeddings）：这是一项在GRU-CM上的消融研究，忽略了结点更新和边更新所涉及的两个步骤，将最大池化操作直接应用于原始的传感器嵌入向量，无需通过GNNs进行组合特异性处理。换句话说，特定组合的active 结点彼此之间不交换消息以适应特定的传感器组合。</li><li>注意，另一个对比模型可能是为每个维度学习一个单独的模型，但这在计算上很昂贵，所需的资源将随着时间序列的维度增长。此外，这样的方法将不能有效地捕获多维间的相关性。</li></ul><h3 id="Result-and-Observations"><a href="#Result-and-Observations" class="headerlink" title="Result and Observations"></a>Result and Observations</h3><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/4.jpg?raw=true" alt="4"></p><ul><li>在zero-shot和微调测试场景中，GRU-CM在三个数据集上的表现都优于普通的GRU。换句话说，在大多数情况下，GRU-CM能够显著缩小GRU-A和GRU之间的差距，证明其鲁棒性可以适应于不可见的传感器组合。</li><li>在zero-shot情形下，GRU-CM要明显优于GRU，fine-tuning也能大大提升GRU和GRU-CM的性能，而相比之下，GRU-CM在fine-tuning数据量不多的时候，更能快速适应，比GRU精度更高。</li><li>随着测试时不可用传感器的比例增加，GRU和GRU-CM的性能都会下降。然而，与GRU相比，GRU-CM性能下降得更为缓慢，体现了conditioning module的优势。</li><li>在与GRU-SE比较的消融实验中，在大多数情况下，GRU-CM的效果优于GRU-SE。此外，GRU-SE有时表现不如普通的GRU。这些观察结果证明了在可用传感器之间传递消息以提供更好的条件向量的重要性。</li></ul><h3 id="Side-Experiment"><a href="#Side-Experiment" class="headerlink" title="Side Experiment"></a>Side Experiment</h3><p>在本实验中，fine-tuning的数据不是来自于测试集，而是取训练集中与测试集里传感器组合有高度重合部分的样本进行微调，并把微调结果和zero-shot情形进行对比。</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/5.jpg?raw=true" alt="5"></p><ul><li>从对比结果可以看出，这种微调方式下，与原来的zero-shot相比，GRU和GRU-CM的结果都有所改善，但GRU-CM的表现仍好于GRU。<strong>这进一步突出了GRU-CM适应新传感器组合的能力，甚至比让GRU针对特定实例进行微调更好。</strong></li></ul><h1 id="7-IDEA"><a href="#7-IDEA" class="headerlink" title="7-IDEA"></a>7-IDEA</h1><ul><li>在GNN中加入注意力机制</li><li>在用高度重叠实例进行fine-tuning时可考虑找多个高重叠度的实例进行集成学习进行互补。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-MOTIVATION&quot;&gt;&lt;a href=&quot;#1-MOTIVATION&quot; class=&quot;headerlink&quot; title=&quot;1-MOTIVATION&quot;&gt;&lt;/a&gt;1-MOTIVATION&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;物联网(IoT)技术的一些应用涉及&lt;u&gt;从
      
    
    </summary>
    
    
      <category term="GNN" scheme="https://jadew0321.github.io/andromeda.github.io/categories/GNN/"/>
    
    
      <category term="paper" scheme="https://jadew0321.github.io/andromeda.github.io/tags/paper/"/>
    
  </entry>
  
</feed>
