<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jade</title>
  
  <subtitle>Notes for Machine Learning</subtitle>
  <link href="/andromeda.github.io/atom.xml" rel="self"/>
  
  <link href="https://jadew0321.github.io/andromeda.github.io/"/>
  <updated>2020-07-22T02:45:56.599Z</updated>
  <id>https://jadew0321.github.io/andromeda.github.io/</id>
  
  <author>
    <name>Jade W</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Graph Attention Networks</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/22/Graph%20Attention%20Networks/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/22/Graph%20Attention%20Networks/</id>
    <published>2020-07-22T02:30:32.000Z</published>
    <updated>2020-07-22T02:45:56.599Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="GNN" scheme="https://jadew0321.github.io/andromeda.github.io/categories/GNN/"/>
    
    
      <category term="paper" scheme="https://jadew0321.github.io/andromeda.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>How to create your personal homepage</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/10/How-to-create-your-personal-homepage/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/10/How-to-create-your-personal-homepage/</id>
    <published>2020-07-10T02:04:59.000Z</published>
    <updated>2020-07-11T03:32:58.630Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>碎碎念：好多之前的博客也是没坚持多久就不接着写下去了，过几天把比较有价值的搬运过来。开始Github Pages也是因为一个很喜欢的师妹，给我看了她自己的网站，简直！酷炫！太符合她的人设啦~ 新鲜感驱使我在一大堆bug里乘风破浪，搭了这个小窝，希望这次可以坚持地久一些。</p></blockquote><h1 id="安装Node"><a href="#安装Node" class="headerlink" title="安装Node"></a>安装Node</h1><ul><li><p>在<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Node</a>官网下载对应版本的软件，按默认方式一路安装直至成功。</p></li><li><p>验证：进入cmd，输入以下代码，如果显示Git版本信息说明安装成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure></li></ul><h1 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h1><ul><li><p>在<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">Git官网</a>下载对应版本的软件，按默认方式一路安装直至成功。</p></li><li><p>验证：进入cmd，输入以下代码，如果显示Git版本信息说明安装成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git --version</span><br></pre></td></tr></table></figure></li><li><p>这时候对任意一个文件夹点右键，会有多出来两个选项“Git GUI Here”和“Git Bash Here”</p></li></ul><h1 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h1><ul><li><p>选择一个存放blog文件的路径，新建文件夹，重命名为你想要的名字，我就用了myblog命名文件夹，鼠标放在myblog文件夹上点右键，选择Git Bash Here（之后很多操作都会从Git Bash Here开始）。依次输入以下命令，安装完输下一个。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p>然后就静静等待他叭啦叭啦装完。</p></li></ul><h1 id="初始化Hexo"><a href="#初始化Hexo" class="headerlink" title="初始化Hexo"></a>初始化Hexo</h1><ul><li><p>执行以下初始化命令，会自动在你命名的文件夹（这里是blog）中新建所需要的文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init blog</span><br><span class="line">cd blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><p>顺利的话，运行下面的命令，在浏览器中输入<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 就可以看到网页的预览效果了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure></li></ul><h1 id="建立Github-Pages"><a href="#建立Github-Pages" class="headerlink" title="建立Github Pages"></a>建立Github Pages</h1><ul><li><p>注册Github就不多说啦，注册完新建repositories，Github只能用一个同名仓库的代码托管一个站点，注意一下就好。</p></li><li><p>repository name 必须是以 github.io结尾，比如我的 andromeda.github.io，硬性规定遵守即可。</p><p>（我这里因为新建过同名仓库了，所以显示不能用这个名字）</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/1.jpg?raw=true" alt="1" style="zoom:50%;"></p></li><li><p>新建仓库完成后，进入该仓库的Settings，查看和熟悉一下，往下拉有个Github Pages，下面这个画横线的站点就是我们创建的个人网页地址，放收藏夹哈之后会一直用到的。选择master branch，如果这个选择是灰的，就先点下一个按键，选一个主题之后就自动master branch啦~</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/3.jpg?raw=true" alt="3"></p><p>先看一眼我踏过千山万水、填过千沟万壑之后的blog成品图</p><p>好搞笑哦，能看到这篇博客的应该也能看到主页吧！多此一举多此一举。go on~</p></li></ul><h1 id="配置SSHkey"><a href="#配置SSHkey" class="headerlink" title="配置SSHkey"></a>配置SSHkey</h1><ul><li><p>要使用git工具首先要配置以下SSH Key，为部署本地博客到Github做准备。在第一次新建的文件夹里面 Git Bash Here 输入以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ~&#x2F;.ssh</span><br></pre></td></tr></table></figure><p>如果没有报错或者提示什么的就说明是以前生成过的，可以直接使用以下命令查看本机SSH Key</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~&#x2F;.ssh&#x2F;id_rsa.pub</span><br></pre></td></tr></table></figure><p>如果之前没有创建，就执行以下命令配置本地账户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name</span><br><span class="line">git config --global user.email</span><br><span class="line">ssh-keygen -t rsa -C user.email</span><br></pre></td></tr></table></figure><p>按照提示敲三次回车，就可以生成啦。再通过cat ~/.ssh/id_rsa.pub查看key就可以了。</p><p>然后需要确认并添加主机到本机SSH可信列表，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>如果返回 Hi XXX！……等一系列话，就说明你添加成功了。接下来去Github网页版右上角点+号，找到Settings-SSH and GPG keys-New SSH key，复制刚刚生成的SSH Key并生成就OK了。命令行窗口可以不用关掉，之后还要来用的！</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/5.png?raw=true" alt="5"></p></li></ul><h1 id="连接Github与本地blog文件"><a href="#连接Github与本地blog文件" class="headerlink" title="连接Github与本地blog文件"></a>连接Github与本地blog文件</h1><ul><li><p>打开博客根目录下的_config.yml 配置文件，拉到最后，在deployment段落中填上以下信息：</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/4.png?raw=true" alt="4"></p><p>第一个大坑来了！！！除了网上各大教程都说了的，要在冒号后面加一个空格之外！！！千万千万千万不要修改type\repository\branch前面的缩进！一定是要在原始的格式上，在冒号后空一格填上你对应的信息……可能大家也没有我这么手贱，去强行缩进和改动，以至于后面一直一直部署不了。</p></li><li><p>修改完之后就可以继续在命令行窗口输入下面的generate代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure></li><li><p>稍等几十秒，最多几分钟，就可以在浏览器上输入你自己的站点，然后看到最原始的博客界面啦！</p></li></ul><h1 id="好看最重要！"><a href="#好看最重要！" class="headerlink" title="好看最重要！"></a>好看最重要！</h1><p>接下来一定是去<a href="https://hexo.io/themes/" target="_blank" rel="noopener">hexo模板官网</a>找一个好看的模板了呀！个人比较喜欢简洁大气的风格，用的是diaspora。之前拍的写真可以派上用场了喜喜。</p><p>不同的模板有不同的安装和配置方法，这里就不详细展开啦，大家自行百度 ”xxx模板 hexo配置“ 基本都可以找到教程，换上自己喜欢的背景图片和logo，一个专属的网页就生成啦！</p><p>具体的写作和数学公式以及图片显示等等细节，可以参看这个<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo中文文档</a>。</p><p><em>最后提醒自己一百遍：坚持坚持坚持！！！</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;碎碎念：好多之前的博客也是没坚持多久就不接着写下去了，过几天把比较有价值的搬运过来。开始Github Pages也是因为一个很喜欢的师妹，给我看了她自己的网站，简直！酷炫！太符合她的人设啦~ 新鲜感驱使我在一大堆bug里乘风破浪，搭了这个小窝，希望
      
    
    </summary>
    
    
      <category term="Hexo" scheme="https://jadew0321.github.io/andromeda.github.io/categories/Hexo/"/>
    
    
      <category term="technique" scheme="https://jadew0321.github.io/andromeda.github.io/tags/technique/"/>
    
  </entry>
  
  <entry>
    <title>Handling Variable-Dimensional Time Series with Graph Neural Networks</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/</id>
    <published>2020-07-09T02:10:20.000Z</published>
    <updated>2020-07-13T02:20:09.069Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-MOTIVATION"><a href="#1-MOTIVATION" class="headerlink" title="1-MOTIVATION"></a>1-MOTIVATION</h1><ul><li><p>物联网(IoT)技术的一些应用涉及<u>从多个传感器捕获数据</u>，从而产生多传感器时间序列。</p></li><li><p>现有的基于神经网络（NN）的多变量时间序列建模方法<u>假设传感器的输入维数（即传感器的数量）是固定的。</u></p></li><li><p>在实际应用中，例如手机、穿戴设备、工业设备等，这些<u>相同设备的不同实例安装的传感器组合通常是不同的</u>，因此无论下游任务是预测还是分类，模型在设计时就<u>需要考虑不同(可变)的输入维度</u>，以构造一个针对某一设备来说<u>较为通用的模型架构</u>。</p></li></ul><h1 id="2-INTRODUCTION"><a href="#2-INTRODUCTION" class="headerlink" title="2-INTRODUCTION"></a>2-INTRODUCTION</h1><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>由于IoT的快速发展，设备范围的不断扩大，多传感器时间序列数据无处不在并且快速增长。深度学习方法已经成功地应用于多元时间序列预测、分类、异常检测和剩余有用寿命估计。</p><h3 id="假设与矛盾"><a href="#假设与矛盾" class="headerlink" title="假设与矛盾"></a>假设与矛盾</h3><p>大多数现有的对多变量时间序列数据建模的方法假设固定维的时间序列作为输入，<u>这在许多实际情况下，这种假设可能并不成立</u>。例如，在学习活动识别模型时，由于穿戴设备实例的不同，不同人的时间序列可能<u>涉及到不同数量的可用传感器</u>(如加速度计、陀螺仪、磁力仪)。类似地，设备运行状况监控模型也需要处理来自不同实例设备的数据，这些<u>实例上安装了不同的传感器</u>(比如温度、振动和压力)。</p><h3 id="针对场景"><a href="#针对场景" class="headerlink" title="针对场景"></a>针对场景</h3><p>在这项工作中，作者考虑了<u>由同一底层动力系统的不同实例</u>(例如在活动识别中的人)生成多个<u>不同传感器组合的多元时间序列分析问题</u>。即网络的输入维度是不确定的，（但不超过某个最大上限）。</p><h3 id="方法优势"><a href="#方法优势" class="headerlink" title="方法优势"></a>方法优势</h3><p>提出的模型在zero-shot （测试集中可用传感器的组合与训练集中的组合都不相同）和fine-tuning （训练集中包含有少量与测试实例相同组合的样本可用于微调）两个设定实验下性能优于普通NN模型，并且通过ablation study验证了模型各个组成成分的有效性。</p><h1 id="3-RELATED-WORKS"><a href="#3-RELATED-WORKS" class="headerlink" title="3-RELATED WORKS"></a>3-RELATED WORKS</h1><h6 id="把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。"><a href="#把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。" class="headerlink" title="把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。"></a>把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。</h6><ul><li>但是随着测试实例中传感器丢失百分比的增加，该方法的性能会迅速下降。</li></ul><h6 id="仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。"><a href="#仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。" class="headerlink" title="仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。"></a>仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。</h6><ul><li>由于它们依赖于时间序列中每个维度至少有一个可用值的情况，因此不适用于整条时间序列缺失的问题设置。</li></ul><h6 id="针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。"><a href="#针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。" class="headerlink" title="针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。"></a>针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。</h6><ul><li>当可能组合的数量呈指数级增长时，网络扩展困难; </li><li>假设每一种组合都有足够的训练数据可用; </li><li>且不同模型训练时不保留任何跨组合的知识。</li></ul><p><em>以上相关方法都有一定的缺陷，因此作者在GNN、transfer-learning、meta-learning的启发下，提出了一种新的神经网络结构，适用于zero-shot 和fine-tuning迁移学习，能够实现在测试时对多变量时间序列进行鲁棒的推理，且这些多变量时间序列中的有效维度（即可用的传感器组合）是未知的。</em></p><h1 id="4-PROBLEM-DEFINITION"><a href="#4-PROBLEM-DEFINITION" class="headerlink" title="4-PROBLEM DEFINITION"></a>4-PROBLEM DEFINITION</h1><p>对本问题场景进行数学上的描述，对于符号达成以下共识：</p><ul><li>考虑一个训练集$\mathcal{D}=\left\{\left(\mathbf{x}_{i}, y_{i}\right)\right\}_{i=1}^{N}$ ，具有$N$个多变量时间序列 $\mathbf{x}_{i} \in \mathcal{X}$ 和对应的标签 $y_i \in \mathcal{Y}$。</li><li>每个时间序列 $\mathbf{x}_{i}=\left\{\mathbf{x}_{i}^{t}\right\}_{t=1}^{T_{i}}$的长度都为 $T_i\in\mathcal{T}$。</li><li>$\mathcal{S}$表示包含所有传感器的集合，共$d$维（即变量最大维度为$d$）；$\mathcal{S}_i \subseteq \mathcal{S}$表示不同的传感器组合，其下标 $i$与 $\mathbf{x}_{i}$ 中的下标对应，表示当前组合包含的可用传感器共$d_i$维，$1 \leq d_{i} \leq d$。</li><li>对于某个时刻$t$来说，$\mathbf{x}_{i}^{t}$ 是 一个 $d_i$ 维的向量，即 $\mathbf{x}_{i}^{t} \in \mathbb{R}^{d_{i}}$。</li><li>下游任务的目标是，学习到 $\mathcal{X}$ 与 $\mathcal{Y}$ 之间的映射关系：$f: \mathcal{X} \rightarrow \mathcal{Y}$。</li></ul><h1 id="5-APPROACH"><a href="#5-APPROACH" class="headerlink" title="5-APPROACH"></a>5-APPROACH</h1><p>作者提出一个新的基于GNN的时间序列分析模型，利用神经网络架构（GRU，当然LSTM也可）与两个全新的模块：</p><ul><li><p>core dynamics module——用于对数据的时序特性进行建模；</p></li><li><p>conditioning module——基于不同的传感器组合，利用GNN学习各可用传感器之间的信息聚合关系，并生产一个“conditioning vector”作为附加输入传递至core dynamic module，对时序特性的建模进行定制化调整。</p></li></ul><p>模型总体架构示意图如下所示：</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/1.jpg?raw=true" alt="1"></p><h3 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h3><ul><li><p>Details</p><p>首先确定最大变量维度d，所有变量组合的维度$1 \leq d{i} \leq d$。如左下角的Input Time Series(x) 所示，对第二维缺失传感器数值的维度进行mean-imputed，即该传感器在其他实例中可用时的平均值，预处理后的多变量时序数据$\mathbf{x}{i}$中每个时刻的输入都是一个d维向量。</p><p><em>这个操作实质上是为了能把等长维度的数据喂给GRU网络作为输入。</em></p></li></ul><h3 id="Conditioning-Module"><a href="#Conditioning-Module" class="headerlink" title="Conditioning Module"></a>Conditioning Module</h3><ul><li><p>Details</p><ul><li><p>在图表示学习的启发下，将每一个可用的传感器看作一个结点（vertices）。两个结点之间的关系定义为边（edges）。对应于包含全部传感器的组合$\mathcal{S}$，考虑用图$\mathcal{G}(\mathcal{V}, \mathcal{E})$来表示，每个$s\in\mathcal{S}$ 对应一个结点$v_s\in \mathcal{V}$，每个结点$v_s$的邻节点用 <script type="math/tex">\mathcal{N}_{\mathcal{G}}\left(v_{s}\right)</script> 表示。</p></li><li><p>每个传感器 $s \in \mathcal{S}$ 与一个可学习的embeding vector（嵌入向量） $v_s\in \mathbb{R}^{d_{s}}$ 相关联。</p></li><li><p>对于一个特定的多个传感器的组合$\mathcal{S}_i$，可用的传感器对应的结点被激活，图中每两个active结点之间连成的边也被为激活（fullly-connected）。因此，就如结构图上GNN框中的三个彩色结点所示，这三个结点以及它们两两之间的边都是激活的。</p></li><li><p>对于不同的组合都有一个确定的图结构，基于图结构我们构造结点更新网络及边更新网络：</p><ul><li><p>node-specific feed-forward network（结点前馈网络）&amp; edge-specific feed-forward network（边前馈网络）</p><p>结点的更新体现了相邻结点对当前结点的聚合作用，具体的，对于任意一个active node$v_k$，对应的结点向量$\mathbf{v}_{k}$的更新公式如下：</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{v}_{k l} &=f_{e}\left(\left[\mathbf{v}_{k}, \mathbf{v}_{l}\right] ; \boldsymbol{\theta}_{e}\right), \quad \forall v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right) \\\tilde{\mathbf{v}}_{k} &=f_{n}\left(\left[\mathbf{v}_{k}, \sum_{\forall l} \mathbf{v}_{k l}\right] ; \boldsymbol{\theta}_{n}\right)\end{aligned}</script><p>其中，$\mathbf{V}_{k l}$表示所有与$v_k$相连的结点$v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right)$对$v_k$产生的作用。</p><p>$\tilde{\mathbf{V}}_{k}$表示$v_k$在聚合了所有$\mathbf{V}_{k l}$对她的影响之后，对自身结点的一个更新。</p><p>$\theta _e$和$\theta _n$分别为$f_e$和$f_n$的可学习参数，简单来说，$f_e$将邻结点信息传递到待更新结点，$f_n$利用邻结点的聚合信息更新相应结点。</p><p><em>另外，$fn$和$fe$在图中所有的结点和边上共享权重系数，也就是说这两个网络训练的不是特定点之间或特定边上的更新方式，而是整个图通用的更新方式。</em></p><p>最后根据更新后的各结点向量得到一个 conditioning vector <script type="math/tex">\mathbf{v}_{\mathcal{S}_{i}} \in \mathbb{R}^{d_{s}}</script></p><script type="math/tex; mode=display">\mathbf{v}_{\mathcal{S}_{i}}=\max \left(\left\{\tilde{\mathbf{v}}_{k}\right\}_{v_{k} \in \mathcal{V}_{i}}\right)</script><p>注意，最大化操作原理同卷积网络中的池化操作，也可用平均值代替，相当于卷积网络中的平均池化，但经过作者实验，发现最大池化效果要优于平均池化，因此采用对$\tilde{\mathbf{V}}_{k}$的每一个维度取最大值操作，得到最终的conditioning vector。</p></li><li><p><em>本模块采用GNN的优势在于，它学习到的是一个通用的所有结点之间的聚合关系，因此不仅可以处理在训练中出现过的组合，在测试时，可以处理训练集中见过的变量组合之外的unseen组合，从而提高了对组合处理的泛化能力，这也是可以应对zero-shot的本质原因。</em></p></li></ul></li></ul></li></ul><h3 id="Core-Dynamics-Module"><a href="#Core-Dynamics-Module" class="headerlink" title="Core Dynamics Module"></a>Core Dynamics Module</h3><ul><li><p>Details</p><ul><li>Core Dynamics Module 包含一个gated RNN模型，文中采用GRU，当然也可以用LSTM等。</li><li>输入时固定维度的多变量时序数据（由于在数据预处理中，我们将缺失的变量用常量进行了填补，并记填补后的输入为$\tilde{\mathbf{x}}_{i}$）。</li><li>与普通的模型输入不同的是，在本模块中，需要把时序数据$\tilde{\mathbf{x}}_{i}$和上面模块中得到的conditioning vector 拼接起来（维度扩展）一起输入GRU进行训练，并与上一时刻的特征向量一起，往下一个时刻进行信息传输，具体公式为：</li></ul><script type="math/tex; mode=display">\mathbf{z}_{i}^{t}=G R U\left(\left[\tilde{\mathbf{x}}_{i}^{t}, \mathbf{v}_{\mathcal{S}_{i}}\right], \mathbf{z}_{i}^{t-1} ; \boldsymbol{\theta}_{G R U}\right), \quad t: 1, \ldots, T_{i}</script><ul><li>在最后一个时刻，得到模型输出的特征向量$\mathbf{z}_{i}^{T_i}$，预测的输出根据不同的下游任务进行构造和确定：<script type="math/tex; mode=display">\hat{y}_{i}=f_{o}\left(\mathbf{z}_{i}^{T_{i}} ; \boldsymbol{\theta}_{o}\right)</script>附上LSTM和GRU的结构图作为参考：</li></ul></li></ul><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/2.png?raw=true" alt="2"></p><h3 id="Training-Rules"><a href="#Training-Rules" class="headerlink" title="Training Rules"></a>Training Rules</h3><ul><li>整个模型通过随机梯度下降（SGD）以end-to-end的形式进行整体的训练。</li><li><p>损失函数：</p><ul><li>分类：<script type="math/tex">\mathcal{L}_{c}=-\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i}^{k} \log \left(\hat{y}_{i}^{k}\right)</script></li><li>预测：<script type="math/tex">\mathcal{L}_{r}=\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2}</script></li></ul></li><li><p><em>注意：该模型参数学习的方式为mini-batch SGD，是在每个mini-batch内输入具有相同变量组合的时间序列进行训练，而整个batch包含多种不同的变量组合。</em></p></li></ul><h1 id="6-EXPERIMENT"><a href="#6-EXPERIMENT" class="headerlink" title="6-EXPERIMENT"></a>6-EXPERIMENT</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><ul><li>DSADS</li><li>HAR</li><li>Turbofan</li></ul><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/3.jpg?raw=true" alt="3"></p><h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><ul><li>Zero-shot setting：把一部分变量组合包含的数据作为训练数据，除训练集外剩下所有unseen的组合作为测试数据，直接使用训练好的网络进行推理。</li><li>Fine-tuning setting：把一部分变量组合包含的数据作为训练数据，使用除训练集外的一部分与测试集相同变量组合的带标记数据来微调网络参数，用剩下的测试数据进行测试。</li><li>$f_{t r}$和$f_{t e}$表示训练和测试过程中每个时间序列不可用传感器的比例，把训练时的比例记为$f_{t r}=\{0.25,0.4\}$，测试时的比例记为$f_{t e}=\{0.1,0.25,0.4,0.5\}$ </li><li>对于所有数据集，40%用于训练，10%用于验证，10%用于微调(在zero-shot情况下忽略)，其余40%用于测试。</li><li>评价指标：分别使用分类错误率和均方根误差(RMSE)作为分类和回归任务的性能指标。</li></ul><h3 id="Hyperparameters-Used"><a href="#Hyperparameters-Used" class="headerlink" title="Hyperparameters Used"></a>Hyperparameters Used</h3><ul><li>core dynamics module 由三层GRU构成，每层GRU各有128个单元，每个结点的嵌入向量维度为d/2。</li><li>mini-batch在训练时和fine-tuning时的大小分别为64和32，所有前馈层之后都有0.2的dropout用于正则化，训练时采用最大150 epoch，微调时采用最大50 epoch。</li><li>使用无动量的vanilla SGD以5e-4的学习率来更新传感器嵌入向量，用Adam以1e-4的学习率来更新的其他层的学习速率。（由于active 结点在每一个mini-batch中都会随着可用传感器组合的变化而变化，我们发现使用vanilla SGD来更新传感器向量是有用的，然而如果我们加入动量，非active结点的向量也会得到更新；另一方面，在所有变量组合和mini-batch共享的GNN和核心模块，都受益于momentum，因此Adam用于更新它们的参数。)</li></ul><h3 id="Baselines-Considered"><a href="#Baselines-Considered" class="headerlink" title="Baselines Considered"></a>Baselines Considered</h3><ul><li>GRU-CM (GRU with GNNbased conditioning module)：文章提出的模型</li><li>GRU：在缺失传感器中填充均值，相当于GRU-CM模型去掉了conditioning module，只有时序模块，因此不会给GRU提供额外的条件向量信号。</li><li>GRU-A（GRU with All Sensors Available）：该模型对于所有的训练和测试实例，可使用所有的传感器的数值，（即无传感器缺失），训练超参数与GRU-CM相同，旨在找出模型精度的一个上届。</li><li>GRU-SE（GRU with Maxpool over Sensor Embeddings）：这是一项在GRU-CM上的消融研究，忽略了结点更新和边更新所涉及的两个步骤，将最大池化操作直接应用于原始的传感器嵌入向量，无需通过GNNs进行组合特异性处理。换句话说，特定组合的active 结点彼此之间不交换消息以适应特定的传感器组合。</li><li>注意，另一个对比模型可能是为每个维度学习一个单独的模型，但这在计算上很昂贵，所需的资源将随着时间序列的维度增长。此外，这样的方法将不能有效地捕获多维间的相关性。</li></ul><h3 id="Result-and-Observations"><a href="#Result-and-Observations" class="headerlink" title="Result and Observations"></a>Result and Observations</h3><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/4.jpg?raw=true" alt="4"></p><ul><li>在zero-shot和微调测试场景中，GRU-CM在三个数据集上的表现都优于普通的GRU。换句话说，在大多数情况下，GRU-CM能够显著缩小GRU-A和GRU之间的差距，证明其鲁棒性可以适应于不可见的传感器组合。</li><li>在zero-shot情形下，GRU-CM要明显优于GRU，fine-tuning也能大大提升GRU和GRU-CM的性能，而相比之下，GRU-CM在fine-tuning数据量不多的时候，更能快速适应，比GRU精度更高。</li><li>随着测试时不可用传感器的比例增加，GRU和GRU-CM的性能都会下降。然而，与GRU相比，GRU-CM性能下降得更为缓慢，体现了conditioning module的优势。</li><li>在与GRU-SE比较的消融实验中，在大多数情况下，GRU-CM的效果优于GRU-SE。此外，GRU-SE有时表现不如普通的GRU。这些观察结果证明了在可用传感器之间传递消息以提供更好的条件向量的重要性。</li></ul><h3 id="Side-Experiment"><a href="#Side-Experiment" class="headerlink" title="Side Experiment"></a>Side Experiment</h3><p>在本实验中，fine-tuning的数据不是来自于测试集，而是取训练集中与测试集里传感器组合有高度重合部分的样本进行微调，并把微调结果和zero-shot情形进行对比。</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/5.jpg?raw=true" alt="5"></p><ul><li>从对比结果可以看出，这种微调方式下，与原来的zero-shot相比，GRU和GRU-CM的结果都有所改善，但GRU-CM的表现仍好于GRU。<strong>这进一步突出了GRU-CM适应新传感器组合的能力，甚至比让GRU针对特定实例进行微调更好。</strong></li></ul><h1 id="7-IDEA"><a href="#7-IDEA" class="headerlink" title="7-IDEA"></a>7-IDEA</h1><ul><li>在GNN中加入注意力机制</li><li>在用高度重叠实例进行fine-tuning时可考虑找多个高重叠度的实例进行集成学习进行互补。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-MOTIVATION&quot;&gt;&lt;a href=&quot;#1-MOTIVATION&quot; class=&quot;headerlink&quot; title=&quot;1-MOTIVATION&quot;&gt;&lt;/a&gt;1-MOTIVATION&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;物联网(IoT)技术的一些应用涉及&lt;u&gt;从
      
    
    </summary>
    
    
      <category term="GNN" scheme="https://jadew0321.github.io/andromeda.github.io/categories/GNN/"/>
    
    
      <category term="paper" scheme="https://jadew0321.github.io/andromeda.github.io/tags/paper/"/>
    
  </entry>
  
</feed>
