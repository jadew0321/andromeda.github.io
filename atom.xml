<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jade</title>
  
  <subtitle>Notes for Machine Learning</subtitle>
  <link href="/andromeda.github.io/atom.xml" rel="self"/>
  
  <link href="https://jadew0321.github.io/andromeda.github.io/"/>
  <updated>2020-07-10T06:40:27.621Z</updated>
  <id>https://jadew0321.github.io/andromeda.github.io/</id>
  
  <author>
    <name>Jade W</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>How to create your personal homepage</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/10/How-to-create-your-personal-homepage/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/10/How-to-create-your-personal-homepage/</id>
    <published>2020-07-10T02:04:59.000Z</published>
    <updated>2020-07-10T06:40:27.621Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/waiting.JPG?raw=true" alt="waiting"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/waiting.JPG?raw=tr
      
    
    </summary>
    
    
      <category term="Hexo" scheme="https://jadew0321.github.io/andromeda.github.io/categories/Hexo/"/>
    
    
      <category term="technique" scheme="https://jadew0321.github.io/andromeda.github.io/tags/technique/"/>
    
  </entry>
  
  <entry>
    <title>Handling Variable-Dimensional Time Series with Graph Neural Networks</title>
    <link href="https://jadew0321.github.io/andromeda.github.io/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/"/>
    <id>https://jadew0321.github.io/andromeda.github.io/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/</id>
    <published>2020-07-09T02:10:20.000Z</published>
    <updated>2020-07-10T06:34:48.804Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MOTIVATION"><a href="#MOTIVATION" class="headerlink" title="MOTIVATION"></a>MOTIVATION</h1><ul><li><p>物联网(IoT)技术的一些应用涉及<u>从多个传感器捕获数据</u>，从而产生多传感器时间序列。</p></li><li><p>现有的基于神经网络（NN）的多变量时间序列建模方法<u>假设传感器的输入维数（即传感器的数量）是固定的。</u></p></li><li><p>在实际应用中，例如手机、穿戴设备、工业设备等，这些<u>相同设备的不同实例安装的传感器组合通常是不同的</u>，因此无论下游任务是预测还是分类，模型在设计时就<u>需要考虑不同(可变)的输入维度</u>，以构造一个针对某一设备来说<u>较为通用的模型架构</u>。</p></li></ul><h1 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h1><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>由于IoT的快速发展，设备范围的不断扩大，多传感器时间序列数据无处不在并且快速增长。深度学习方法已经成功地应用于多元时间序列预测、分类、异常检测和剩余有用寿命估计。</p><h3 id="假设与矛盾"><a href="#假设与矛盾" class="headerlink" title="假设与矛盾"></a>假设与矛盾</h3><p>大多数现有的对多变量时间序列数据建模的方法假设固定维的时间序列作为输入，<u>这在许多实际情况下，这种假设可能并不成立</u>。例如，在学习活动识别模型时，由于穿戴设备实例的不同，不同人的时间序列可能<u>涉及到不同数量的可用传感器</u>(如加速度计、陀螺仪、磁力仪)。类似地，设备运行状况监控模型也需要处理来自不同实例设备的数据，这些<u>实例上安装了不同的传感器</u>(比如温度、振动和压力)。</p><h3 id="针对场景"><a href="#针对场景" class="headerlink" title="针对场景"></a>针对场景</h3><p>在这项工作中，作者考虑了<u>由同一底层动力系统的不同实例</u>(例如在活动识别中的人)生成多个<u>不同传感器组合的多元时间序列分析问题</u>。即网络的输入维度是不确定的，（但不超过某个最大上限）。</p><h3 id="方法优势"><a href="#方法优势" class="headerlink" title="方法优势"></a>方法优势</h3><p>提出的模型在zero-shot （测试集中可用传感器的组合与训练集中的组合都不相同）和fine-tuning （训练集中包含有少量与测试实例相同组合的样本可用于微调）两个设定实验下性能优于普通NN模型，并且通过ablation study验证了模型各个组成成分的有效性。</p><h1 id="RELATED-WORKS"><a href="#RELATED-WORKS" class="headerlink" title="RELATED WORKS"></a>RELATED WORKS</h1><ul><li>把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。<ul><li>但是随着测试实例中传感器丢失百分比的增加，该方法的性能会迅速下降。</li></ul></li><li>仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。<ul><li>由于它们依赖于时间序列中每个维度至少有一个可用值的情况，因此不适用于整条时间序列缺失的问题设置。</li></ul></li><li>针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。<ul><li>当可能组合的数量呈指数级增长时，网络扩展困难; </li><li>假设每一种组合都有足够的训练数据可用; </li><li>且不同模型训练时不保留任何跨组合的知识。</li></ul></li></ul><p><em>以上相关方法，都有一定的缺陷，因此作者在GNN、transfer-learning、meta-learning的启发下，提出了一种新的神经网络结构，适用于zero-shot 和fine-tuning迁移学习，能够实现在测试时对多变量时间序列进行鲁棒的推理，且这些多变量时间序列中的有效维度（即可用的传感器组合）是未知的。</em></p><h1 id="PROBLEM-DEFINITION"><a href="#PROBLEM-DEFINITION" class="headerlink" title="PROBLEM DEFINITION"></a>PROBLEM DEFINITION</h1><p>对本问题场景进行数学上的描述，对于符号达成以下共识：</p><ul><li>考虑一个训练集 $\mathcal{D}={(x_i,y_i)}^N_{i=1}$，具有$N$个多变量的时间序列 $x_i \in \mathcal{X}$ 和对应的标签 $y_i \in \mathcal{Y}$。</li><li>每个时间序列 $\mathbf{x}_{i}=\left\{\mathbf{x}_{i}^{t}\right\}_{t=1}^{T_{i}}$的长度都为 $T_i\in\mathcal{T}$。</li><li>$\mathcal{S}$表示包含所有传感器的集合，共$d$维（即变量最大维度为$d$）；$\mathcal{S}_i \subseteq \mathcal{S}$表示不同的传感器组合，其下标 $i$与 $\mathbf{x}_{i}$ 中的下标对应，表示当前组合包含的可用传感器共$d_i$维，$1 \leq d_{i} \leq d$。</li><li>对于某个时刻$t$来说，$\mathbf{x}_{i}^{t}$ 是 一个 $d_i$ 维的向量，即 $\mathbf{x}_{i}^{t} \in \mathbb{R}^{d_{i}}$。</li><li>下游任务的目标是，学习到 $\mathcal{X}$ 与 $\mathcal{Y}$ 之间的映射关系：$f: \mathcal{X} \rightarrow \mathcal{Y}$。</li></ul><h1 id="APPROACH"><a href="#APPROACH" class="headerlink" title="APPROACH"></a>APPROACH</h1><p>作者提出一个新的基于GNN的时间序列分析模型，利用神经网络架构（GRU，当然LSTM也可）与两个全新的模块：</p><ul><li><p>core dynamics module——用于对数据的时序特性进行建模；</p></li><li><p>conditioning module——基于不同的传感器组合，利用GNN学习各可用传感器之间的信息聚合关系，并生产一个“conditioning vector”作为附加输入传递至core dynamic module，对时序特性的建模进行定制化调整。</p></li></ul><p>模型总体架构示意图如下所示：</p><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/1.jpg?raw=true" alt="1"></p><h2 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h2><ul><li><p>Details</p><p>首先确定最大变量维度d，所有变量组合的维度$1 \leq d{i} \leq d$。如左下角的Input Time Series(x) 所示，对第二维缺失传感器数值的维度进行mean-imputed，即该传感器在其他实例中可用时的平均值，预处理后的多变量时序数据$\mathbf{x}{i}$中每个时刻的输入都是一个d维向量。</p><p><em>这个操作实质上是为了能把等长维度的数据喂给GRU网络作为输入。</em></p></li></ul><h2 id="Conditioning-Module"><a href="#Conditioning-Module" class="headerlink" title="Conditioning Module"></a>Conditioning Module</h2><ul><li><p>Details</p><ul><li><p>在图表示学习的启发下，将每一个可用的传感器看作一个结点（vertices）。两个结点之间的关系定义为边（edges）。对应于包含全部传感器的组合$\mathcal{S}$，考虑用图$\mathcal{G}(\mathcal{V}, \mathcal{E})$来表示，每个$s\in\mathcal{S}$ 对应一个结点$v_s\in \mathcal{V}$，每个结点$v_s$的邻节点用 <script type="math/tex">\mathcal{N}_{\mathcal{G}}\left(v_{s}\right)</script> 表示。</p></li><li><p>每个传感器$s\in \mathcal{S}$与一个<u>可学习的embeding vector嵌入向量$v_s\in</u> \mathbb{R}^{d_{s}}$相关联。</p></li><li><p>对于一个特定的多个传感器的组合$\mathcal{S}_i$，可用的传感器对应的结点被激活，图中每两个active结点之间连成的边也被为激活（fullly-connected）。因此，就如结构图上GNN框中的三个彩色结点所示，这三个结点以及它们两两之间的边都是激活的。</p></li><li><p>对于不同的组合都有一个确定的图结构，基于图结构我们构造结点更新网络及边更新网络：</p><ul><li><p>node-specific feed-forward network（结点前馈网络）&amp; edge-specific feed-forward network（边前馈网络）</p><p>结点的更新体现了相邻结点对当前结点的聚合作用，具体的，对于任意一个active node$v_k$，对应的结点向量$\mathbf{v}_{k}$的更新公式如下：</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{v}_{k l} &=f_{e}\left(\left[\mathbf{v}_{k}, \mathbf{v}_{l}\right] ; \boldsymbol{\theta}_{e}\right), \quad \forall v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right) \\\tilde{\mathbf{v}}_{k} &=f_{n}\left(\left[\mathbf{v}_{k}, \sum_{\forall l} \mathbf{v}_{k l}\right] ; \boldsymbol{\theta}_{n}\right)\end{aligned}</script><p>其中，$\mathbf{V}_{k l}$表示所有与$v_k$相连的结点$v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right)$对$v_k$产生的作用。</p><p>$\tilde{\mathbf{V}}_{k}$表示$v_k$在聚合了所有$\mathbf{V}_{k l}$对她的影响之后，对自身结点的一个更新。</p><p>$\theta _e$和$\theta _n$分别为$f_e$和$f_n$的可学习参数，简单来说，$f_e$将邻结点信息传递到待更新结点，$f_n$利用邻结点的聚合信息更新相应结点。</p><p><em>另外，$fn$和$fe$在图中所有的结点和边上共享权重系数，也就是说这两个网络训练的不是特定点之间或特定边上的更新方式，而是整个图通用的更新方式。</em></p><p>最后根据更新后的各结点向量得到一个combination-specific conditioning vector <script type="math/tex">\mathbf{v}_{\mathcal{S}_{i}} \in \mathbb{R}^{d_{s}}</script></p><script type="math/tex; mode=display">\mathbf{v}_{\mathcal{S}_{i}}=\max \left(\left\{\tilde{\mathbf{v}}_{k}\right\}_{v_{k} \in \mathcal{V}_{i}}\right)</script><p>注意，最大化操作原理同卷积网络中的池化操作，也可用平均值代替，相当于卷积网络中的平均池化，但经过作者实验，发现最大池化效果要优于平均池化，因此采用对$\tilde{\mathbf{V}}_{k}$的每一个维度取最大值操作，得到最终的conditioning vector。</p></li><li><p><em>本模块采用GNN的优势在于，它学习到的是一个通用的所有结点之间的聚合关系，因此不仅可以处理在训练中出现过的组合，在测试时，可以处理训练集中见过的变量组合之外的unseen组合，从而提高了对组合处理的泛化能力，这也是可以应对zero-shot的本质原因。</em></p></li></ul></li></ul></li></ul><h2 id="Core-Dynamics-Module"><a href="#Core-Dynamics-Module" class="headerlink" title="Core Dynamics Module"></a>Core Dynamics Module</h2><ul><li><p>Details</p><ul><li>Core Dynamics Module 包含一个gated RNN模型，文中采用GRU，当然也可以用LSTM等。</li><li>输入时固定维度的多变量时序数据（由于在数据预处理中，我们将缺失的变量用常量进行了填补，并记填补后的输入为$\tilde{\mathbf{x}}_{i}$）。</li><li>与普通的模型输入不同的是，在本模块中，需要把时序数据$\tilde{\mathbf{x}}_{i}$和上面模块中得到的conditioning vector 拼接起来（维度扩展）一起输入GRU进行训练，并与上一时刻的特征向量一起，往下一个时刻进行信息传输，具体公式为：</li></ul><script type="math/tex; mode=display">\mathbf{z}_{i}^{t}=G R U\left(\left[\tilde{\mathbf{x}}_{i}^{t}, \mathbf{v}_{\mathcal{S}_{i}}\right], \mathbf{z}_{i}^{t-1} ; \boldsymbol{\theta}_{G R U}\right), \quad t: 1, \ldots, T_{i}</script><ul><li>在最后一个时刻，得到模型输出的特征向量$\mathbf{z}_{i}^{T_i}$，预测的输出根据不同的下游任务进行构造和确定：<script type="math/tex; mode=display">\hat{y}_{i}=f_{o}\left(\mathbf{z}_{i}^{T_{i}} ; \boldsymbol{\theta}_{o}\right)</script>附上LSTM和GRU的结构图作为参考：</li></ul></li></ul><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/2.png?raw=true" alt="2"></p><h3 id="Training-Rules"><a href="#Training-Rules" class="headerlink" title="Training Rules"></a>Training Rules</h3><ul><li>整个模型通过随机梯度下降（SGD）以end-to-end的形式进行整体的训练。</li><li><p>损失函数：</p><ul><li>分类：<script type="math/tex">\mathcal{L}_{c}=-\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i}^{k} \log \left(\hat{y}_{i}^{k}\right)</script></li><li>预测：<script type="math/tex">\mathcal{L}_{r}=\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2}</script></li></ul></li><li><p><em>注意：该模型参数学习的方式为mini-batch SGD，是在每个mini-batch内输入具有相同变量组合的时间序列进行训练，而整个batch包含多种不同的变量组合。</em></p></li></ul><h1 id="EXPERIMENT"><a href="#EXPERIMENT" class="headerlink" title="EXPERIMENT"></a>EXPERIMENT</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><ul><li>DSADS</li><li><p>HAR</p></li><li><p>Turbofan</p></li></ul><h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><ul><li>Zero-shot setting：把一部分变量组合包含的数据作为训练数据，除训练集外剩下所有unseen的组合作为测试数据，直接使用训练好的网络进行推理。</li><li>Fine-tuning setting：把一部分变量组合包含的数据作为训练数据，使用除训练集外的一部分与测试集相同变量组合的带标记数据来微调网络参数，用剩下的测试数据进行测试。</li><li>$f_{t r}$和$f_{t e}$表示训练和测试过程中每个时间序列不可用传感器的比例，令$f_{t r}=\{0.25,0.4\}$，且$f_{t e}=\{0.1,0.25,0.4,0.5\}$。</li></ul><h3 id="Case-1"><a href="#Case-1" class="headerlink" title="Case #1"></a>Case #1</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MOTIVATION&quot;&gt;&lt;a href=&quot;#MOTIVATION&quot; class=&quot;headerlink&quot; title=&quot;MOTIVATION&quot;&gt;&lt;/a&gt;MOTIVATION&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;物联网(IoT)技术的一些应用涉及&lt;u&gt;从多个传感器捕获数
      
    
    </summary>
    
    
      <category term="GNN" scheme="https://jadew0321.github.io/andromeda.github.io/categories/GNN/"/>
    
    
      <category term="paper" scheme="https://jadew0321.github.io/andromeda.github.io/tags/paper/"/>
    
  </entry>
  
</feed>
