<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Handling Variable-Dimensional Time Series with Graph Neural Networks</title>
    <url>/andromeda.github.io/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/</url>
    <content><![CDATA[<h1 id="1-MOTIVATION"><a href="#1-MOTIVATION" class="headerlink" title="1-MOTIVATION"></a>1-MOTIVATION</h1><ul>
<li><p>物联网(IoT)技术的一些应用涉及<u>从多个传感器捕获数据</u>，从而产生多传感器时间序列。</p>
</li>
<li><p>现有的基于神经网络（NN）的多变量时间序列建模方法<u>假设传感器的输入维数（即传感器的数量）是固定的。</u></p>
</li>
<li><p>在实际应用中，例如手机、穿戴设备、工业设备等，这些<u>相同设备的不同实例安装的传感器组合通常是不同的</u>，因此无论下游任务是预测还是分类，模型在设计时就<u>需要考虑不同(可变)的输入维度</u>，以构造一个针对某一设备来说<u>较为通用的模型架构</u>。</p>
</li>
</ul>
<h1 id="2-INTRODUCTION"><a href="#2-INTRODUCTION" class="headerlink" title="2-INTRODUCTION"></a>2-INTRODUCTION</h1><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>由于IoT的快速发展，设备范围的不断扩大，多传感器时间序列数据无处不在并且快速增长。深度学习方法已经成功地应用于多元时间序列预测、分类、异常检测和剩余有用寿命估计。</p>
<h3 id="假设与矛盾"><a href="#假设与矛盾" class="headerlink" title="假设与矛盾"></a>假设与矛盾</h3><p>大多数现有的对多变量时间序列数据建模的方法假设固定维的时间序列作为输入，<u>这在许多实际情况下，这种假设可能并不成立</u>。例如，在学习活动识别模型时，由于穿戴设备实例的不同，不同人的时间序列可能<u>涉及到不同数量的可用传感器</u>(如加速度计、陀螺仪、磁力仪)。类似地，设备运行状况监控模型也需要处理来自不同实例设备的数据，这些<u>实例上安装了不同的传感器</u>(比如温度、振动和压力)。</p>
<h3 id="针对场景"><a href="#针对场景" class="headerlink" title="针对场景"></a>针对场景</h3><p>在这项工作中，作者考虑了<u>由同一底层动力系统的不同实例</u>(例如在活动识别中的人)生成多个<u>不同传感器组合的多元时间序列分析问题</u>。即网络的输入维度是不确定的，（但不超过某个最大上限）。</p>
<h3 id="方法优势"><a href="#方法优势" class="headerlink" title="方法优势"></a>方法优势</h3><p>提出的模型在zero-shot （测试集中可用传感器的组合与训练集中的组合都不相同）和fine-tuning （训练集中包含有少量与测试实例相同组合的样本可用于微调）两个设定实验下性能优于普通NN模型，并且通过ablation study验证了模型各个组成成分的有效性。</p>
<h1 id="3-RELATED-WORKS"><a href="#3-RELATED-WORKS" class="headerlink" title="3-RELATED WORKS"></a>3-RELATED WORKS</h1><h6 id="把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。"><a href="#把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。" class="headerlink" title="把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。"></a>把传感器个数的变化看作是缺失值，常用的处理时间序列实例中传感器丢失的方法是根据其他实例中传感器可用时的统计数据，为该缺失传感器假定一个常数值（通常是均值）。</h6><ul>
<li>但是随着测试实例中传感器丢失百分比的增加，该方法的性能会迅速下降。</li>
</ul>
<h6 id="仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。"><a href="#仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。" class="headerlink" title="仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。"></a>仍然是把传感器个数的变化看作是缺失值，一般使用平滑、插值和样条等数据填充方法。</h6><ul>
<li>由于它们依赖于时间序列中每个维度至少有一个可用值的情况，因此不适用于整条时间序列缺失的问题设置。</li>
</ul>
<h6 id="针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。"><a href="#针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。" class="headerlink" title="针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。"></a>针对不同的传感器组合，为每一种可能的组合训练不同结构和参数的网络。</h6><ul>
<li>当可能组合的数量呈指数级增长时，网络扩展困难; </li>
<li>假设每一种组合都有足够的训练数据可用; </li>
<li>且不同模型训练时不保留任何跨组合的知识。</li>
</ul>
<p><em>以上相关方法都有一定的缺陷，因此作者在GNN、transfer-learning、meta-learning的启发下，提出了一种新的神经网络结构，适用于zero-shot 和fine-tuning迁移学习，能够实现在测试时对多变量时间序列进行鲁棒的推理，且这些多变量时间序列中的有效维度（即可用的传感器组合）是未知的。</em></p>
<h1 id="4-PROBLEM-DEFINITION"><a href="#4-PROBLEM-DEFINITION" class="headerlink" title="4-PROBLEM DEFINITION"></a>4-PROBLEM DEFINITION</h1><p>对本问题场景进行数学上的描述，对于符号达成以下共识：</p>
<ul>
<li>考虑一个训练集$\mathcal{D}=\left\{\left(\mathbf{x}_{i}, y_{i}\right)\right\}_{i=1}^{N}$ ，具有$N$个多变量时间序列 $\mathbf{x}_{i} \in \mathcal{X}$ 和对应的标签 $y_i \in \mathcal{Y}$。</li>
<li>每个时间序列 $\mathbf{x}_{i}=\left\{\mathbf{x}_{i}^{t}\right\}_{t=1}^{T_{i}}$的长度都为 $T_i\in\mathcal{T}$。</li>
<li>$\mathcal{S}$表示包含所有传感器的集合，共$d$维（即变量最大维度为$d$）；$\mathcal{S}_i \subseteq \mathcal{S}$表示不同的传感器组合，其下标 $i$与 $\mathbf{x}_{i}$ 中的下标对应，表示当前组合包含的可用传感器共$d_i$维，$1 \leq d_{i} \leq d$。</li>
<li>对于某个时刻$t$来说，$\mathbf{x}_{i}^{t}$ 是 一个 $d_i$ 维的向量，即 $\mathbf{x}_{i}^{t} \in \mathbb{R}^{d_{i}}$。</li>
<li>下游任务的目标是，学习到 $\mathcal{X}$ 与 $\mathcal{Y}$ 之间的映射关系：$f: \mathcal{X} \rightarrow \mathcal{Y}$。</li>
</ul>
<h1 id="5-APPROACH"><a href="#5-APPROACH" class="headerlink" title="5-APPROACH"></a>5-APPROACH</h1><p>作者提出一个新的基于GNN的时间序列分析模型，利用神经网络架构（GRU，当然LSTM也可）与两个全新的模块：</p>
<ul>
<li><p>core dynamics module——用于对数据的时序特性进行建模；</p>
</li>
<li><p>conditioning module——基于不同的传感器组合，利用GNN学习各可用传感器之间的信息聚合关系，并生产一个“conditioning vector”作为附加输入传递至core dynamic module，对时序特性的建模进行定制化调整。</p>
</li>
</ul>
<p>模型总体架构示意图如下所示：</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/1.jpg?raw=true" alt="1"></p>
<h3 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h3><ul>
<li><p>Details</p>
<p>首先确定最大变量维度d，所有变量组合的维度$1 \leq d{i} \leq d$。如左下角的Input Time Series(x) 所示，对第二维缺失传感器数值的维度进行mean-imputed，即该传感器在其他实例中可用时的平均值，预处理后的多变量时序数据$\mathbf{x}{i}$中每个时刻的输入都是一个d维向量。</p>
<p><em>这个操作实质上是为了能把等长维度的数据喂给GRU网络作为输入。</em></p>
</li>
</ul>
<h3 id="Conditioning-Module"><a href="#Conditioning-Module" class="headerlink" title="Conditioning Module"></a>Conditioning Module</h3><ul>
<li><p>Details</p>
<ul>
<li><p>在图表示学习的启发下，将每一个可用的传感器看作一个结点（vertices）。两个结点之间的关系定义为边（edges）。对应于包含全部传感器的组合$\mathcal{S}$，考虑用图$\mathcal{G}(\mathcal{V}, \mathcal{E})$来表示，每个$s\in\mathcal{S}$ 对应一个结点$v_s\in \mathcal{V}$，每个结点$v_s$的邻节点用 <script type="math/tex">\mathcal{N}_{\mathcal{G}}\left(v_{s}\right)</script> 表示。</p>
</li>
<li><p>每个传感器 $s \in \mathcal{S}$ 与一个可学习的embeding vector（嵌入向量） $v_s\in \mathbb{R}^{d_{s}}$ 相关联。</p>
</li>
<li><p>对于一个特定的多个传感器的组合$\mathcal{S}_i$，可用的传感器对应的结点被激活，图中每两个active结点之间连成的边也被为激活（fullly-connected）。因此，就如结构图上GNN框中的三个彩色结点所示，这三个结点以及它们两两之间的边都是激活的。</p>
</li>
<li><p>对于不同的组合都有一个确定的图结构，基于图结构我们构造结点更新网络及边更新网络：</p>
<ul>
<li><p>node-specific feed-forward network（结点前馈网络）&amp; edge-specific feed-forward network（边前馈网络）</p>
<p>结点的更新体现了相邻结点对当前结点的聚合作用，具体的，对于任意一个active node$v_k$，对应的结点向量$\mathbf{v}_{k}$的更新公式如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{v}_{k l} &=f_{e}\left(\left[\mathbf{v}_{k}, \mathbf{v}_{l}\right] ; \boldsymbol{\theta}_{e}\right), \quad \forall v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right) \\
\tilde{\mathbf{v}}_{k} &=f_{n}\left(\left[\mathbf{v}_{k}, \sum_{\forall l} \mathbf{v}_{k l}\right] ; \boldsymbol{\theta}_{n}\right)
\end{aligned}</script><p>其中，$\mathbf{V}_{k l}$表示所有与$v_k$相连的结点$v_{l} \in \mathcal{N}_{\mathcal{G}}\left(v_{k}\right)$对$v_k$产生的作用。</p>
<p>$\tilde{\mathbf{V}}_{k}$表示$v_k$在聚合了所有$\mathbf{V}_{k l}$对她的影响之后，对自身结点的一个更新。</p>
<p>$\theta _e$和$\theta _n$分别为$f_e$和$f_n$的可学习参数，简单来说，$f_e$将邻结点信息传递到待更新结点，$f_n$利用邻结点的聚合信息更新相应结点。</p>
<p><em>另外，$fn$和$fe$在图中所有的结点和边上共享权重系数，也就是说这两个网络训练的不是特定点之间或特定边上的更新方式，而是整个图通用的更新方式。</em></p>
<p>最后根据更新后的各结点向量得到一个 conditioning vector <script type="math/tex">\mathbf{v}_{\mathcal{S}_{i}} \in \mathbb{R}^{d_{s}}</script></p>
<script type="math/tex; mode=display">
\mathbf{v}_{\mathcal{S}_{i}}=\max \left(\left\{\tilde{\mathbf{v}}_{k}\right\}_{v_{k} \in \mathcal{V}_{i}}\right)</script><p>注意，最大化操作原理同卷积网络中的池化操作，也可用平均值代替，相当于卷积网络中的平均池化，但经过作者实验，发现最大池化效果要优于平均池化，因此采用对$\tilde{\mathbf{V}}_{k}$的每一个维度取最大值操作，得到最终的conditioning vector。</p>
</li>
<li><p><em>本模块采用GNN的优势在于，它学习到的是一个通用的所有结点之间的聚合关系，因此不仅可以处理在训练中出现过的组合，在测试时，可以处理训练集中见过的变量组合之外的unseen组合，从而提高了对组合处理的泛化能力，这也是可以应对zero-shot的本质原因。</em></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Core-Dynamics-Module"><a href="#Core-Dynamics-Module" class="headerlink" title="Core Dynamics Module"></a>Core Dynamics Module</h3><ul>
<li><p>Details</p>
<ul>
<li>Core Dynamics Module 包含一个gated RNN模型，文中采用GRU，当然也可以用LSTM等。</li>
<li>输入时固定维度的多变量时序数据（由于在数据预处理中，我们将缺失的变量用常量进行了填补，并记填补后的输入为$\tilde{\mathbf{x}}_{i}$）。</li>
<li>与普通的模型输入不同的是，在本模块中，需要把时序数据$\tilde{\mathbf{x}}_{i}$和上面模块中得到的conditioning vector 拼接起来（维度扩展）一起输入GRU进行训练，并与上一时刻的特征向量一起，往下一个时刻进行信息传输，具体公式为：</li>
</ul>
<script type="math/tex; mode=display">
\mathbf{z}_{i}^{t}=G R U\left(\left[\tilde{\mathbf{x}}_{i}^{t}, \mathbf{v}_{\mathcal{S}_{i}}\right], \mathbf{z}_{i}^{t-1} ; \boldsymbol{\theta}_{G R U}\right), \quad t: 1, \ldots, T_{i}</script><ul>
<li>在最后一个时刻，得到模型输出的特征向量$\mathbf{z}_{i}^{T_i}$，预测的输出根据不同的下游任务进行构造和确定：<script type="math/tex; mode=display">
\hat{y}_{i}=f_{o}\left(\mathbf{z}_{i}^{T_{i}} ; \boldsymbol{\theta}_{o}\right)</script>附上LSTM和GRU的结构图作为参考：</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/2.png?raw=true" alt="2"></p>
<h3 id="Training-Rules"><a href="#Training-Rules" class="headerlink" title="Training Rules"></a>Training Rules</h3><ul>
<li>整个模型通过随机梯度下降（SGD）以end-to-end的形式进行整体的训练。</li>
<li><p>损失函数：</p>
<ul>
<li>分类：<script type="math/tex">\mathcal{L}_{c}=-\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i}^{k} \log \left(\hat{y}_{i}^{k}\right)</script></li>
<li>预测：<script type="math/tex">\mathcal{L}_{r}=\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2}</script></li>
</ul>
</li>
<li><p><em>注意：该模型参数学习的方式为mini-batch SGD，是在每个mini-batch内输入具有相同变量组合的时间序列进行训练，而整个batch包含多种不同的变量组合。</em></p>
</li>
</ul>
<h1 id="6-EXPERIMENT"><a href="#6-EXPERIMENT" class="headerlink" title="6-EXPERIMENT"></a>6-EXPERIMENT</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><ul>
<li>DSADS</li>
<li>HAR</li>
<li>Turbofan</li>
</ul>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/3.jpg?raw=true" alt="3"></p>
<h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><ul>
<li>Zero-shot setting：把一部分变量组合包含的数据作为训练数据，除训练集外剩下所有unseen的组合作为测试数据，直接使用训练好的网络进行推理。</li>
<li>Fine-tuning setting：把一部分变量组合包含的数据作为训练数据，使用除训练集外的一部分与测试集相同变量组合的带标记数据来微调网络参数，用剩下的测试数据进行测试。</li>
<li>$f_{t r}$和$f_{t e}$表示训练和测试过程中每个时间序列不可用传感器的比例，把训练时的比例记为$f_{t r}=\{0.25,0.4\}$，测试时的比例记为$f_{t e}=\{0.1,0.25,0.4,0.5\}$ </li>
<li>对于所有数据集，40%用于训练，10%用于验证，10%用于微调(在zero-shot情况下忽略)，其余40%用于测试。</li>
<li>评价指标：分别使用分类错误率和均方根误差(RMSE)作为分类和回归任务的性能指标。</li>
</ul>
<h3 id="Hyperparameters-Used"><a href="#Hyperparameters-Used" class="headerlink" title="Hyperparameters Used"></a>Hyperparameters Used</h3><ul>
<li>core dynamics module 由三层GRU构成，每层GRU各有128个单元，每个结点的嵌入向量维度为d/2。</li>
<li>mini-batch在训练时和fine-tuning时的大小分别为64和32，所有前馈层之后都有0.2的dropout用于正则化，训练时采用最大150 epoch，微调时采用最大50 epoch。</li>
<li>使用无动量的vanilla SGD以5e-4的学习率来更新传感器嵌入向量，用Adam以1e-4的学习率来更新的其他层的学习速率。（由于active 结点在每一个mini-batch中都会随着可用传感器组合的变化而变化，我们发现使用vanilla SGD来更新传感器向量是有用的，然而如果我们加入动量，非active结点的向量也会得到更新；另一方面，在所有变量组合和mini-batch共享的GNN和核心模块，都受益于momentum，因此Adam用于更新它们的参数。)</li>
</ul>
<h3 id="Baselines-Considered"><a href="#Baselines-Considered" class="headerlink" title="Baselines Considered"></a>Baselines Considered</h3><ul>
<li>GRU-CM (GRU with GNNbased conditioning module)：文章提出的模型</li>
<li>GRU：在缺失传感器中填充均值，相当于GRU-CM模型去掉了conditioning module，只有时序模块，因此不会给GRU提供额外的条件向量信号。</li>
<li>GRU-A（GRU with All Sensors Available）：该模型对于所有的训练和测试实例，可使用所有的传感器的数值，（即无传感器缺失），训练超参数与GRU-CM相同，旨在找出模型精度的一个上届。</li>
<li>GRU-SE（GRU with Maxpool over Sensor Embeddings）：这是一项在GRU-CM上的消融研究，忽略了结点更新和边更新所涉及的两个步骤，将最大池化操作直接应用于原始的传感器嵌入向量，无需通过GNNs进行组合特异性处理。换句话说，特定组合的active 结点彼此之间不交换消息以适应特定的传感器组合。</li>
<li>注意，另一个对比模型可能是为每个维度学习一个单独的模型，但这在计算上很昂贵，所需的资源将随着时间序列的维度增长。此外，这样的方法将不能有效地捕获多维间的相关性。</li>
</ul>
<h3 id="Result-and-Observations"><a href="#Result-and-Observations" class="headerlink" title="Result and Observations"></a>Result and Observations</h3><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/4.jpg?raw=true" alt="4"></p>
<ul>
<li>在zero-shot和微调测试场景中，GRU-CM在三个数据集上的表现都优于普通的GRU。换句话说，在大多数情况下，GRU-CM能够显著缩小GRU-A和GRU之间的差距，证明其鲁棒性可以适应于不可见的传感器组合。</li>
<li>在zero-shot情形下，GRU-CM要明显优于GRU，fine-tuning也能大大提升GRU和GRU-CM的性能，而相比之下，GRU-CM在fine-tuning数据量不多的时候，更能快速适应，比GRU精度更高。</li>
<li>随着测试时不可用传感器的比例增加，GRU和GRU-CM的性能都会下降。然而，与GRU相比，GRU-CM性能下降得更为缓慢，体现了conditioning module的优势。</li>
<li>在与GRU-SE比较的消融实验中，在大多数情况下，GRU-CM的效果优于GRU-SE。此外，GRU-SE有时表现不如普通的GRU。这些观察结果证明了在可用传感器之间传递消息以提供更好的条件向量的重要性。</li>
</ul>
<h3 id="Side-Experiment"><a href="#Side-Experiment" class="headerlink" title="Side Experiment"></a>Side Experiment</h3><p>在本实验中，fine-tuning的数据不是来自于测试集，而是取训练集中与测试集里传感器组合有高度重合部分的样本进行微调，并把微调结果和zero-shot情形进行对比。</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/09/Handling-Variable-Dimensional-Time-Series-with-Graph-Neural-Networks/5.jpg?raw=true" alt="5"></p>
<ul>
<li>从对比结果可以看出，这种微调方式下，与原来的zero-shot相比，GRU和GRU-CM的结果都有所改善，但GRU-CM的表现仍好于GRU。<strong>这进一步突出了GRU-CM适应新传感器组合的能力，甚至比让GRU针对特定实例进行微调更好。</strong></li>
</ul>
<h1 id="7-IDEA"><a href="#7-IDEA" class="headerlink" title="7-IDEA"></a>7-IDEA</h1><ul>
<li>在GNN中加入注意力机制</li>
<li>在用高度重叠实例进行fine-tuning时可考虑找多个高重叠度的实例进行集成学习进行互补。</li>
</ul>
]]></content>
      <categories>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>How to create your personal homepage</title>
    <url>/andromeda.github.io/2020/07/10/How-to-create-your-personal-homepage/</url>
    <content><![CDATA[<blockquote>
<p>碎碎念：好多之前的博客也是没坚持多久就不接着写下去了，过几天把比较有价值的搬运过来。开始Github Pages也是因为一个很喜欢的师妹，给我看了她自己的网站，简直！酷炫！太符合她的人设啦~ 新鲜感驱使我在一大堆bug里乘风破浪，搭了这个小窝，希望这次可以坚持地久一些。</p>
</blockquote>
<h1 id="安装Node"><a href="#安装Node" class="headerlink" title="安装Node"></a>安装Node</h1><ul>
<li><p>在<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Node</a>官网下载对应版本的软件，按默认方式一路安装直至成功。</p>
</li>
<li><p>验证：进入cmd，输入以下代码，如果显示Git版本信息说明安装成功。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h1><ul>
<li><p>在<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">Git官网</a>下载对应版本的软件，按默认方式一路安装直至成功。</p>
</li>
<li><p>验证：进入cmd，输入以下代码，如果显示Git版本信息说明安装成功。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git --version</span><br></pre></td></tr></table></figure>
</li>
<li><p>这时候对任意一个文件夹点右键，会有多出来两个选项“Git GUI Here”和“Git Bash Here”</p>
</li>
</ul>
<h1 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h1><ul>
<li><p>选择一个存放blog文件的路径，新建文件夹，重命名为你想要的名字，我就用了myblog命名文件夹，鼠标放在myblog文件夹上点右键，选择Git Bash Here（之后很多操作都会从Git Bash Here开始）。依次输入以下命令，安装完输下一个。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<p>然后就静静等待他叭啦叭啦装完。</p>
</li>
</ul>
<h1 id="初始化Hexo"><a href="#初始化Hexo" class="headerlink" title="初始化Hexo"></a>初始化Hexo</h1><ul>
<li><p>执行以下初始化命令，会自动在你命名的文件夹（这里是blog）中新建所需要的文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init blog</span><br><span class="line">cd blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>
<p>顺利的话，运行下面的命令，在浏览器中输入<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 就可以看到网页的预览效果了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="建立Github-Pages"><a href="#建立Github-Pages" class="headerlink" title="建立Github Pages"></a>建立Github Pages</h1><ul>
<li><p>注册Github就不多说啦，注册完新建repositories，Github只能用一个同名仓库的代码托管一个站点，注意一下就好。</p>
</li>
<li><p>repository name 必须是以 github.io结尾，比如我的 andromeda.github.io，硬性规定遵守即可。</p>
<p>（我这里因为新建过同名仓库了，所以显示不能用这个名字）</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/1.jpg?raw=true" alt="1" style="zoom:50%;"></p>
</li>
<li><p>新建仓库完成后，进入该仓库的Settings，查看和熟悉一下，往下拉有个Github Pages，下面这个画横线的站点就是我们创建的个人网页地址，放收藏夹哈之后会一直用到的。选择master branch，如果这个选择是灰的，就先点下一个按键，选一个主题之后就自动master branch啦~</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/3.jpg?raw=true" alt="3"></p>
<p>先看一眼我踏过千山万水、填过千沟万壑之后的blog成品图</p>
<p>好搞笑哦，能看到这篇博客的应该也能看到主页吧！多此一举多此一举。go on~</p>
</li>
</ul>
<h1 id="配置SSHkey"><a href="#配置SSHkey" class="headerlink" title="配置SSHkey"></a>配置SSHkey</h1><ul>
<li><p>要使用git工具首先要配置以下SSH Key，为部署本地博客到Github做准备。在第一次新建的文件夹里面 Git Bash Here 输入以下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~&#x2F;.ssh</span><br></pre></td></tr></table></figure>
<p>如果没有报错或者提示什么的就说明是以前生成过的，可以直接使用以下命令查看本机SSH Key</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat ~&#x2F;.ssh&#x2F;id_rsa.pub</span><br></pre></td></tr></table></figure>
<p>如果之前没有创建，就执行以下命令配置本地账户</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global user.name</span><br><span class="line">git config --global user.email</span><br><span class="line">ssh-keygen -t rsa -C user.email</span><br></pre></td></tr></table></figure>
<p>按照提示敲三次回车，就可以生成啦。再通过cat ~/.ssh/id_rsa.pub查看key就可以了。</p>
<p>然后需要确认并添加主机到本机SSH可信列表，输入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>
<p>如果返回 Hi XXX！……等一系列话，就说明你添加成功了。接下来去Github网页版右上角点+号，找到Settings-SSH and GPG keys-New SSH key，复制刚刚生成的SSH Key并生成就OK了。命令行窗口可以不用关掉，之后还要来用的！</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/5.png?raw=true" alt="5"></p>
</li>
</ul>
<h1 id="连接Github与本地blog文件"><a href="#连接Github与本地blog文件" class="headerlink" title="连接Github与本地blog文件"></a>连接Github与本地blog文件</h1><ul>
<li><p>打开博客根目录下的_config.yml 配置文件，拉到最后，在deployment段落中填上以下信息：</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/10/How-to-create-your-personal-homepage/4.png?raw=true" alt="4"></p>
<p>第一个大坑来了！！！除了网上各大教程都说了的，要在冒号后面加一个空格之外！！！千万千万千万不要修改type\repository\branch前面的缩进！一定是要在原始的格式上，在冒号后空一格填上你对应的信息……可能大家也没有我这么手贱，去强行缩进和改动，以至于后面一直一直部署不了。</p>
</li>
<li><p>修改完之后就可以继续在命令行窗口输入下面的generate代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>
</li>
<li><p>稍等几十秒，最多几分钟，就可以在浏览器上输入你自己的站点，然后看到最原始的博客界面啦！</p>
</li>
</ul>
<h1 id="好看最重要！"><a href="#好看最重要！" class="headerlink" title="好看最重要！"></a>好看最重要！</h1><p>接下来一定是去<a href="https://hexo.io/themes/" target="_blank" rel="noopener">hexo模板官网</a>找一个好看的模板了呀！个人比较喜欢简洁大气的风格，用的是diaspora。之前拍的写真可以派上用场了喜喜。</p>
<p>不同的模板有不同的安装和配置方法，这里就不详细展开啦，大家自行百度 ”xxx模板 hexo配置“ 基本都可以找到教程，换上自己喜欢的背景图片和logo，一个专属的网页就生成啦！</p>
<p>具体的写作和数学公式以及图片显示等等细节，可以参看这个<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo中文文档</a>。</p>
<p><em>最后提醒自己一百遍：坚持坚持坚持！！！</em></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>technique</tag>
      </tags>
  </entry>
  <entry>
    <title>Multistep Speed Prediction on Traffic Networks-A Graph Convolutional Sequence-to-Sequence Learning Approach with Attention Mechanism</title>
    <url>/andromeda.github.io/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文为了捕获多步交通状况预测中复杂的非平稳时间动态和空间依赖性，提出了一种新的深度学习框架——attention graph convolutional sequence-to-sequence model (AGC-Seq2Seq)。在AGC-Seq2Seq中，空间和时间的依赖关系分别通过Seq2Seq模型和图卷积网络进行建模。提出了基于Seq2Seq架构的注意力机制以及新的训练方法，从而克服交通流多步预测的困难，进而能捕捉到交通模式的时间异质性（temporal heterogeneity）。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h3 id="Backgroud"><a href="#Backgroud" class="headerlink" title="Backgroud"></a>Backgroud</h3><p>技术和经济的稳定发展，使得汽车的使用在过去的几十年里有了显著的增长。然而，汽车使用的增加导致了交通拥堵、交通事故、能源过度消耗、碳排放等一系列社会问题。智能交通系统(The intelligent transportation system，ITS)被认为是一个改善交通管理和服务的有效解决方案。高精度的基于交通预测的应用不仅有利于出行者的路线规划和出发时间安排，而且能为交通控制提供有价值的信息，从而提高交通效率和安全。未来的一些研究重点有：</p>
<ol>
<li>对交通网络的流量预测应该得到更多的重视；</li>
<li>采用多步法进行中长期预测更适合实际应用；</li>
<li>可结合交通流时间特性和空间特性进行研究。</li>
</ol>
<h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><ol>
<li>非平稳时变交通模式的的随机性和不确定性；</li>
<li>非欧几里得拓扑结构的数据；</li>
<li>多步预测固有的困难。</li>
</ol>
<h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><ol>
<li>同时提取时域和空域的特征，引入了注意机制以克服多步预测的挑战及捕捉城市交通模式的时间异质性；</li>
<li>设计了一种针对多步交通预测的Seq2Seq模型的训练方法，主要通过在端到端的深度学习框架中协调多维特征和时空速度变量的方法，使得测试期间的输入与训练期间一致；</li>
<li>探究了不同预测步长和路段下交通情况时间和空间变化的相关性。</li>
</ol>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><ol>
<li><h5 id="Road-Network-Topology"><a href="#Road-Network-Topology" class="headerlink" title="Road Network Topology"></a>Road Network Topology</h5><p>交通网数据可以用一个关于行驶方向的图$\mathcal{G}\left(\mathcal{N},\mathcal{L}\right)$来表示，其中$\mathcal{N}$表示路口，边$\mathcal{L}$表示路段。$\boldsymbol{A}$是路段的邻接矩阵，$\boldsymbol{A}\left(i,j\right)$表示路段$i$ 和路段$j$ 的相互连接关系，（值为1表示按行驶方向连接，为0则表示不连接）。网络拓扑结构如下图所示：</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_13-44-53.png?raw=true" alt="Snipaste_2020-07-25_13-44-53" style="zoom: 80%;"></p>
</li>
<li><h5 id="Traffic-Speed"><a href="#Traffic-Speed" class="headerlink" title="Traffic Speed"></a>Traffic Speed</h5><p>交通速度信息：在路段$l_i \left( \forall l_i\in\mathcal{L}\right)$ ，时间段 $t^{th}$的交通速度定义为该路段该时间间隔内浮动车辆的平均速度，记为 $v^i_t$。在时间段 $t^{th}$的交通速度定义为向量 $\boldsymbol{V}_t\in\mathfrak{R^{\left|\mathcal{L}\right|}}$，并且 $\left(\boldsymbol{V}_t\right)_i=v^i_t$。</p>
</li>
<li><h5 id="Time-of-Day-and-Weekday-or-Weekend"><a href="#Time-of-Day-and-Weekday-or-Weekend" class="headerlink" title="Time-of-Day and Weekday-or-Weekend"></a>Time-of-Day and Weekday-or-Weekend</h5><p>由于将每个路段的速度汇总为5min内的平均值，因此将时间也转换为有序整数$N$，例如00：00-00：05，记为 $N_t=1$，7：00-7：05记为 $N_t =85\left(7\times 12+1\right)$ 。工作日或周末的信息用一个虚拟变量 $p_t$ 来区分。</p>
</li>
<li><h5 id="Historical-Statistic-Information"><a href="#Historical-Statistic-Information" class="headerlink" title="Historical Statistic Information"></a>Historical Statistic Information</h5><p>通过将历史统计信息引入预测模型，可以获取交通状态的日变化趋势。历史平均速度、平均速度、最大速度、最小速度、和标准偏差在时间段$t^{th}$道路段$l_i$被定义为训练集中的平均值，中位数，最大值，最小值和标准偏差。分别记为：$v^i_{t,average}$，$v^i_{t,median}$，$v^i_{t,max}$，$v^i_t,min$ 和 $d^i_t$。</p>
</li>
<li><h5 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h5><p>交通速度预测的任务是利用以前观测到的速度记录来预测某一时间段内各路段的未来值。多步交通速度问题可以表示为：</p>
<script type="math/tex; mode=display">
\hat{\boldsymbol{V}}_{t+n}=argmax \Pr \left(\boldsymbol{V}_{t+n}|\boldsymbol{V}_t,\boldsymbol{V}_{t-1},...,\boldsymbol{V}_{t-m};\mathcal{G}\right)</script><p>其中 $\hat{\boldsymbol{V}}_{t+n}$  表示第$n$步的预测值，$\left\{\boldsymbol{V}_t,\boldsymbol{V}_{t-1},…,\boldsymbol{V}_{t-m}|m=1,2,…\right\}$  表示相关的先前观测值向量，$\Pr\left(\cdot|\cdot\right)$  是条件概率函数。</p>
</li>
</ol>
<h3 id="Graph-Convolution-on-Traffic-Networks"><a href="#Graph-Convolution-on-Traffic-Networks" class="headerlink" title="Graph Convolution on Traffic Networks"></a>Graph Convolution on Traffic Networks</h3><ol>
<li><h5 id="定义每个路段-l-i-in-mathcal-L-的邻阶接节点"><a href="#定义每个路段-l-i-in-mathcal-L-的邻阶接节点" class="headerlink" title="定义每个路段 $l_i \in  \mathcal{L}$ 的邻阶接节点"></a>定义每个路段 $l_i \in  \mathcal{L}$ 的邻阶接节点</h5><p> $\mathcal{H_i}\left(K\right)=\left\{l_j \in\mathcal{L}|d\left(l_i,l_j\right)\leq{K}\right\}$，其中$d\left(l_i,l_j\right)$表示从$l_i$走到$l_j$需要的最小边的数量。</p>
</li>
<li><h5 id="定义-K-阶邻接矩阵"><a href="#定义-K-阶邻接矩阵" class="headerlink" title="定义$K$阶邻接矩阵"></a>定义$K$阶邻接矩阵</h5><p>典型邻接矩阵即1-hop邻接矩阵 $\boldsymbol{A}$，$K$阶邻接矩阵可以通过计算1-hop邻接矩阵 $\boldsymbol{A}$的$K$次幂得到，并且为了模拟拉普拉斯矩阵，使对角线元素为1，同时使拓扑图中的卷积具有自可访问性。计算公式如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{A}^K_{GC}=Ci\left(\boldsymbol{A}^K+\boldsymbol{I}\right)</script><p>其中，$Ci\left(\cdot\right)$使得矩阵中每个不为零的元素值为1，因此如果$l_j$属于$l_i$的$K$阶邻接节点，$l_j \in \mathcal{H}_i\left(K\right)$，或者$i=j$，则$\boldsymbol{A}^K_{GC}\left(i,j\right)=1$，否则，$\boldsymbol{A}^K_{GC}\left(i,j\right)=0$ 。</p>
</li>
<li><h5 id="定义图卷积运算"><a href="#定义图卷积运算" class="headerlink" title="定义图卷积运算"></a>定义图卷积运算</h5><script type="math/tex; mode=display">
\boldsymbol{V}_t\left(K\right)=\left(\boldsymbol{W}_{GC}\bigodot\boldsymbol{A}^K_{GC}\right)\cdot\boldsymbol{V}_t</script><p>其中，$\boldsymbol{W}_{GC}$是一个可训练的矩阵，与$\boldsymbol{A}$的大小相同。$\bigodot$表示Hadamard 乘积，实现矩阵对应元素相乘操作。</p>
<p>通过该乘积，会产生一个新的矩阵在$K$阶邻接位置上的可训练参数，而参数在非领域位置上的值为0。</p>
</li>
<li><h5 id="空域离散卷积"><a href="#空域离散卷积" class="headerlink" title="空域离散卷积"></a>空域离散卷积</h5><p>根据上式可以发现，K阶邻接节点对应的训练参数不为0，而其余不相邻节点的训练参数为0，因此对时刻所有路段的交通速度向量$\boldsymbol{V}_t$的空域离散卷积可以通过下式实现：</p>
<script type="math/tex; mode=display">
\left(\boldsymbol{W}_{GC}\bigodot\boldsymbol{A}^K_{GC}\right)\cdot\boldsymbol{V}_t</script><p>因此，$\boldsymbol{V}_t\left(K\right)$称为$t$时刻的空间聚合速度向量，其中的第$i$个元素表示路段$l_i \in \mathcal{L}$在$t$时刻的空间聚合速度，它聚合了来自$K$阶邻接路段的相关信息。</p>
<p>上面的矩阵运算也可以通过下式一维运算来实现：</p>
<script type="math/tex; mode=display">
v^i_t\left(K\right)=\left(\boldsymbol{W}_{GC}\left[i\right]\bigodot\boldsymbol{A}^K_{GC}\left[i\right]\right)^T\cdot\boldsymbol{V}_t</script><p>$\boldsymbol{W}_{GC}\left[i\right]$和$\boldsymbol{A}^K_{GC}\left[i\right]$是 $\boldsymbol{W}_{GC}$和$\boldsymbol{A}^K_{GC}$中的第$i$行。</p>
<p>对$\boldsymbol{A}^K_{GC}\left[i\right]$的理解可参照下图所示例子，其中红线表示当前路段，蓝色表示邻接路段：</p>
<p>（个人觉得图（b）左图，$l_{16}=1$，不知道是不是作者漏了）</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_15-33-10.png?raw=true" alt="Snipaste_2020-07-25_15-33-10" style="zoom: 50%;"></p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_15-37-46.png?raw=true" alt="Snipaste_2020-07-25_15-37-46" style="zoom: 50%;"></p>
</li>
<li><h5 id="AGC-Seq2Seq-Model"><a href="#AGC-Seq2Seq-Model" class="headerlink" title="AGC-Seq2Seq Model"></a>AGC-Seq2Seq Model</h5><p>为了捕捉时间序列特征并获得多步预测输出，我们采用Seq2Seq模型作为整个方法的基本结构。Seq2Seq模型由两个参数独立、相互连接的RNN模块组成。为了克服RNN输出时间戳固定的问题，Seq2Seq模型对编码器部分的时间序列输入进行编码以使其满足时间依赖，解码器根据 context vector 组织以时间步长排列顺序的目标输出。模型结构如下图所示：</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_15-54-53.png?raw=true" alt="Snipaste_2020-07-25_15-54-53" style="zoom: 67%;"></p>
<ul>
<li><p>首先，使用图卷积操作来捕获各路段空间上的特性，生成spatial-temporal variable $v^i_{t-j}\left(K\right)$。</p>
</li>
<li><p>其次，与包含一天中的时段信息$N_t$，以及weekday-or-weekend信息$p_t$ 的 exogenous variable ，$\boldsymbol{E}_{t-j}$进行拼接，来构造一个输入向量，该输入向量后续将喂给Seq2Seq模型的编码器部分。</p>
<p>上述两步操作可通过如下公式实现：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
v_{t-j}^{i}(K)=\left(\boldsymbol{W}_{G C}[i] \odot \boldsymbol{A}_{G C}^{K}[i]\right)^{T} \cdot \boldsymbol{V}_{t-j}, \quad 0 \leq j \leq m \\
\boldsymbol{E}_{t-j}=\left[N_{t-j} ; p_{t-j}\right] \\
\boldsymbol{X}_{t-j}^{i}=\left[v_{t-j}^{i}(K) ; \boldsymbol{E}_{t-j}\right]
\end{array}</script><p>其中，$\left[\cdot;\cdot\right]$表示将两个tensor在相同维度上进行拼接。</p>
</li>
<li><p>接着，在编码器部分，在$t-j,j\in \left\{ 0,…,m\right\} $时刻，前一个时刻的隐藏状态$\boldsymbol{h}_{t-j-1}$传递到了当前时刻，与当前时刻的输入$\boldsymbol{X}_{t-j}$一起计算当前时刻的隐藏状态$\boldsymbol{h}_{t-j}$。如图所示，context vector $\boldsymbol{C}$ 聚合了编码器中所有的信息，包括隐藏状态$\left(\boldsymbol{h}_{t-m}, \boldsymbol{h}_{t-m+1}, \cdots, \boldsymbol{h}_{t-1}\right)$，和输入$\left(\boldsymbol{X}_{t-m}, \boldsymbol{X}_{t-m+1}, \cdots, \boldsymbol{X}_{t}\right)$，作为编码器和解码器的连接者。</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\boldsymbol{h}_{t-j}=\left\{\begin{array}{c}
\text { Cell }_{\text {encoder }}\left(\boldsymbol{h}_{0}, \boldsymbol{X}_{t-j}\right), \\
\text { Cell }_{\text {encoder }}\left(\boldsymbol{h}_{t-j-1}, \boldsymbol{X}_{t-j}\right),
\end{array}\right. & \begin{array}{l}
j=m \\
j \in\{0, \cdots, m-1\}
\end{array} \\
\boldsymbol{C}=\boldsymbol{h}_{t}
\end{array}</script><p>其中$\boldsymbol{h}_0$是初始隐藏状态，设置为零向量。$\text{Cell}_\text{encoder}(\cdot)$是由所采用的RNN结构决定的编码器的计算函数。</p>
</li>
<li><p>然后，在解码器部分，核心的想法是利用context vector $\boldsymbol{C}$作为初始隐藏状态，将输出序列一步一步进行解码。因此，在$t+j, j\in\left\{1,…,n\right\}$时刻，隐藏状态$\boldsymbol{h}_{t+j}$不仅包含输入信息，也考虑了之前时刻的输出状态 $\left(\boldsymbol{h}_{t+1},\boldsymbol{h}_{t+2},…,\boldsymbol{h}_{t+j-1}\right)$ 。</p>
</li>
<li><p>解码器的输入根据不同的训练方法确定：</p>
<ul>
<li><p>Teacher forcing： 是自然语言处理中常用的一种训练策略。在该训练策略中，目标序列被输入到解码器进行训练，在测试阶段，使用之前生成的预测序列作为之后时间戳的输入。</p>
<p>然而，该方法不适用于时间序列问题，主要是由于解码器输入在训练周期和测试周期之间的分布不一致。</p>
</li>
<li><p>Scheduled sampling：计划抽样可用来缓解上述问题，计划抽样随机选择模板序列或之前的预测值，以某个设置好的概率大小喂给模型。</p>
<p>然而，该方法会增加模型复杂度，加重计算负担。</p>
</li>
<li><p>提出方法：为了克服上述问题，文章提出一种新的训练方法，使用历史统计信息和time-of-day作为输入。在时间序列预测问题中，在训练和测试阶段都可以获得历史统计信息；基于这样的事实，解码器输入在训练和测试期间的分布将会同步，从而解决了Teacher forcing的困境。此外，由于历史统计信息在多步预测中至关重要，将其加入到模型中有望提高预测精度。</p>
</li>
<li><p>解码器在$t+j$时刻的输出将通过下式计算：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\boldsymbol{v}_{t+j}^{i}(H)=\left[N_{t+j} ; v_{t+j, \text {average}}^{i} ; v_{t+j, m e d i a n}^{i} ; v_{t+j, m a x}^{i} ; v_{t+j, m i n}^{i}, d_{t+j}^{i}\right] \\
\boldsymbol{h}_{t+j}=\left\{\begin{aligned}
\operatorname{Cell}_{\text {decoder }}\left(\boldsymbol{C}, \boldsymbol{v}_{t+j}^{i}(H)\right), j=1 & \\
\text { Cell }_{\text {decoder }}\left(\boldsymbol{h}_{t+j-1}, \boldsymbol{v}_{t+j}^{i}(H)\right), j \in\{2, \cdots, n\}
\end{aligned}\right.
\end{array}</script></li>
</ul>
</li>
<li><p>在实际模型构件中，我们采用门控循环单元(GRU)作为编码器和解码器的内部结构。内部运算结构如下图所示：</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_16-37-41.png?raw=true" alt="Snipaste_2020-07-25_16-37-41" style="zoom: 67%;"></p>
<p>计算公式为：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
z_{t}=\sigma\left(W_{z} \cdot\left[\boldsymbol{h}_{t-1} ; x_{t}\right]+b_{z}\right) \\
r_{t}=\sigma\left(\boldsymbol{W}_{r} \cdot\left[\boldsymbol{h}_{t-1} ; x_{t}\right]+b_{r}\right) \\
c_{t}=\tanh \left(\boldsymbol{W}_{c} \cdot\left[r_{t} \odot \boldsymbol{h}_{t-1} ; x_{t}\right]+b_{c}\right) \\
\boldsymbol{h}_{t}=\left(1-z_{t}\right) \odot \boldsymbol{h}_{t-1}+z_{t} \odot \boldsymbol{c}_{t} \\
\sigma(x)=\frac{1}{1+e^{-x}} \\
\tanh (x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
\end{array}</script></li>
<li><p>加入注意力机制以捕捉交通模态中的时序异质性：关键是为每一个时间步增加一个注意力向量，用于捕捉源侧信息的相关性，以帮助预测交通速度。</p>
<p>在$t+j$时刻，注意力函数计算$\boldsymbol{h}_{t+j}$和一系列隐藏状态$\left(\boldsymbol{h}_{t-m}, \boldsymbol{h}_{t-m+1}, \cdots, \boldsymbol{h}_{t}\right)$之前的相似度，得到一个注意力向量$\boldsymbol{S}_{t+j}$。该注意力向量是这一系列隐藏状态的加权线性组合。加权系数及注意力向量的计算公式如下：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
u_{t+j}^{t-i}=\boldsymbol{q}^{T} \tanh \left(\boldsymbol{h}_{t+j} \boldsymbol{W}_{f} \boldsymbol{h}_{t-i}\right), i=0,1, \cdots, m \\
a_{t+j}^{t-i}=\operatorname{softmax}\left(u_{t+j}^{t-i}\right)=\frac{\exp \left(u_{t+j}^{t-i}\right)}{\sum_{r=1}^{m} \exp \left(u_{t+j}^{t-r}\right)}, i=0,1, \cdots, m \\
\boldsymbol{S}_{t+j}=\sum_{i=1}^{m} a_{t+j}^{t-i} \boldsymbol{h}_{t-i}
\end{array}</script><p>其中，$u_{t+j}^{t-i}$用于衡量两个隐藏状态之间的相似性，$\boldsymbol{q}^{T}$和$\boldsymbol{W}_{f}$是可训练的权重矩阵和向量。$a_{t+j}^{t-i}$ 是 $u_{t+j}^{t-i}$ 归一化后的值，进一步作为权重系数。</p>
<p>最终根据注意力向量$\boldsymbol{S}_{t+j}$和原始的当前隐藏状态$\boldsymbol{h}_{t+j}$，得到一个注意隐藏状态，$\boldsymbol{\tilde{h}}_{t+j}$，计算公式如下：</p>
<script type="math/tex; mode=display">
\widetilde{\boldsymbol{h}}_{t+j}=\tanh \left(\boldsymbol{W}_{h} \cdot\left[\boldsymbol{S}_{t+k} ; \boldsymbol{h}_{t+j}\right]\right)</script></li>
<li><p>预测输出</p>
<p>最后将注意隐藏状态进行线性变换后作为预测输出：</p>
<script type="math/tex; mode=display">
\hat{v}_{t+j}=\boldsymbol{W}_{v} \widetilde{\boldsymbol{h}}_{t+j}+b_{v}</script></li>
<li><p>LOSS</p>
<p>为了同时降低多步预测中的预测误差，我们将损失定义为$\left(\hat{v}_{t+1}, \hat{v}_{t+2}, \cdots, \hat{v}_{t+n}\right)$和$\left(v_{t+1}, v_{t+2}, \cdots, v_{t+n}\right)$之间的平均绝对误差：</p>
<script type="math/tex; mode=display">
\operatorname{loss} =\frac{1}{n} \sum_{j=1}^{n}\left|\hat{v}_{t+j}^{i}-v_{t+j}^{i}\right|</script><p>在训练阶段通过小批量梯度下降算法最小化损失函数来更新所有参数。</p>
</li>
</ul>
</li>
</ol>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>选择2018年搜狐统计的北京二环路段的交通数据进行实验验证。二环路全长33公里，我们将其分为163段，每段长200米。此外，计算每个路段的5分钟平均速度。训练和测试集分配如下：</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_17-07-08.png?raw=true" alt="Snipaste_2020-07-25_17-07-08" style="zoom:67%;"></p>
<h3 id="Evaluation-statistics"><a href="#Evaluation-statistics" class="headerlink" title="Evaluation statistics"></a>Evaluation statistics</h3><p>我们通过三个经典的误差指标来评估模型:</p>
<ol>
<li>平均绝对百分比误差(MAPE)；</li>
<li>平均绝对误差(MAE)；</li>
<li>均方根误差(RMSE)；</li>
</ol>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><ol>
<li><p>AGC-Seq2Seq模型在所有预测区间内的所有指标都优于其他基准。</p>
</li>
<li><p>HA模型的表现不会随预测范围的增加而改变，因为它只依赖于历史数据。</p>
</li>
<li><p>由于交通状态在5分钟内相对稳定，所以在5分钟预测范围内所有模型的性能相似。</p>
</li>
<li><p>与传统的机器学习模型相比，深度学习方法具有更好的预测性能，但计算时间更长。</p>
</li>
<li><p>GCN(根据空间相关性建模)优于LSTM(捕捉时间特征)，证明了考虑空间相关性在交通速度预测中很重要。</p>
</li>
<li><p>AGC-Seq2Seq模型相比GCN和Seq2Seq-Att有明显的改进；这强调了同时捕获时空特征对交通速度预测的重要性。但AGC-Seq2Seq模型的运行时间仅略高于GCN和 Seq2Seq-Att，这主要得益于GPU模块中先进的并行计算技术。</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_17-13-50.png?raw=true" alt="Snipaste_2020-07-25_17-13-50" style="zoom:67%;"></p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_17-14-04.png?raw=true" alt="Snipaste_2020-07-25_17-14-04" style="zoom:67%;"></p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_17-14-18.png?raw=true" alt="Snipaste_2020-07-25_17-14-18" style="zoom:67%;"></p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_17-14-32.png?raw=true" alt="Snipaste_2020-07-25_17-14-32" style="zoom:67%;"></p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/25/Multistep-Speed-Prediction-on-Traffic-Networks/Snipaste_2020-07-25_17-15-06.png?raw=true" alt="Snipaste_2020-07-25_17-15-06" style="zoom:67%;"></p>
</li>
</ol>
<h1 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h1><p>为了解决多步交通速度预测的挑战，本文致力于提出一种复杂的深度学习方法，即AGC-Seq2Seq模型。该模型结合Seq2Seq架构和图形卷积操作来学习交通网络的时空相关性。并且将注意力机制集成到模型中以捕捉交通模式的时间异质性，采用新设计的方法对整个模型结构进行训练。为了验证提出的模型的有效性，我们将其与几个基准测试模型进行比较，包括HA、ARIMA、XGBOOST、ANN, LSTM, SVR, KNN, GCN, Seq2Seq-Att。结果表明，该模型在不同预测区间下的RMSE、MAE和MAPE指标均优于基准模型。在此基础上，进一步探讨了特征的重要性、空间信息对多步预测的影响以及交通时间模式与注意系数的相关性。实验结果表明，随着预测区间的增大，过去一小时的速度特征的相对重要性和空间信息增加的效应逐渐减弱；对于交通状况变化较快的路段，过去15分钟内的回望观测值对应的注意系数值较高。</p>
<p>未来的研究可以包括对大型城市道路网络的实验，以及将交通流理论进一步整合到预测模型中，例如在更复杂的模型中利用交通流的传播波来确定空间邻居。从应用的角度来看，该框架可以与先进的交通管理系统集成，例如，提供系统级的实时路由服务，以减少高峰时段拥堵。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Dynamic Graph Representation Learning via Self-Attention Networks</title>
    <url>/andromeda.github.io/2020/07/26/Dynamic-Graph-Representation-Learning-via-Self-Attention-Networks/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>以前的图表示学习方法主要关注静态图，即图结构固定不变的情形。然而，许多真实世界的图是动态的，并且会随着时间的推移而变化。在本文中提出了动态自注意网络(DySAT)，用于处理动态图来学习节点特征，同时考虑图结构属性和时间演化特性。具体来说，DySAT通过在邻接节点和时间动态特性两个维度上联合使用自注意层来计算节点特征表示。我们对通信网络和双向评级网络进行了边预测实验。实验结果表明，在几种最新的图嵌入基准下，DySAT具有显著的性能提升。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><p>随着图表示学习的广泛发展，学习图节点的特征成为了一个基本的学习任务，其基本思想是学习每个节点的低维向量，该向量 <em>encoder</em> 节点及其邻域（可能还有属性）的结构特性。学习到的的特征表示有利于大量的图分析任务，如节点分类、链接预测、推荐和图可视化等。</p>
</li>
<li><p>以往对图表示学习的研究主要集中在静态图上，静态图包含一组固定的节点和边。然而，现实应用中的许多图在本质上是动态的，图结构可以随时间发展演变。图形结构的变化可以表示为一系列不同时间步长的图形快照。</p>
<p>例如，学术合著网络中，作者可能会定期改变他们的合作行为，电子邮件通信网络的结构可能会因为突发事件而发生巨大变化。在这种情况下，对图结构的时序演变模式进行建模，有利于准确预测节点属性和边预测任务。</p>
</li>
<li><p>与静态图的设定相比，由于复杂的时变图结构，学习动态节点特征很具有挑战性：节点和边都可以新增和消失，邻域可以合并和分离。这就要求学习到的节点特征不仅要保持节点在图结构上的靠近，同时要随着时间的推移捕捉时序相关性。</p>
</li>
<li><p>动态图结构建模问题相关工作：</p>
<ol>
<li><p>使用时间规则化器来加强相邻图结构快照中节点表示的平滑性。</p>
<p>缺点：当节点表现出明显不同的进化行为时，方法可能会失效。</p>
</li>
<li><p>进展：在多关系知识图中使用递归神经结构进行时间推理。</p>
<p>缺点：时序节点特征仅限于一阶邻接节点建模，忽略了高阶图邻域的结构。</p>
</li>
</ol>
</li>
<li><p>注意力机制最近在许多连续学习任务中取得了巨大的成功，如机器翻译和阅读理解，其关键是学习聚合可变大小输入的函数，同时关注与特定上下文最相关的部分。</p>
<p>当注意机制使用单一序列作为输入和上下文时，它通常被称为自我注意。自我注意机制也被迅速扩展到图表示学习中，使每个节点都能参与到它的邻居中，取得了静态图中半监督节点分类任务中最先进的结果。</p>
<p>由于动态图通常包含周期性的模式，如周期性的边或邻域，注意力机制能够利用最相关的历史信息，以促进未来的预测。</p>
</li>
<li><p>本文提出了DySAT模型来学习动态图上的节点表示。具体地说，是在结构邻域和时间动态性这两个维度上使用自我注意力机制，通过考虑其邻接节点的特征以及历史的中心节点特征为节点生成动态表示。</p>
<p>与静态图表示学习不同，DySAT模型可以学习动态节点表示，反映了图结构的时间演化特性。与基于时间平滑的动态图学习方法相比，DySAT能够学习到从细粒化的节点层面捕捉时序特性的注意力权重。</p>
</li>
</ul>
<h1 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h1><ul>
<li>动态的图结构用一系列观察到的图结构的快照来表示：$\mathbb{G}=\left\{\mathcal{G}^{1}, \ldots, \mathcal{G}^{T}\right\}$，其中$T$表示总的时间步。</li>
<li>在$t$时刻，图结构的快照可看作是一个具有共享节点集$\mathcal{V}$，共享边集$\mathcal{E}^t$，加权邻接矩阵$\boldsymbol{A}^t$的加权无向图 $\mathcal{G}_{t}=\left(\mathcal{V}, \mathcal{E}^{t}\right)$。</li>
<li>同时支持边随时间添加和删除。</li>
<li>动态图表示学习的目的是学习到每个结点$v\in\mathcal{V}$在时间步$t=1,2,…,T$上的特征表示 $e^t_v\in \mathbb{R}^d$。</li>
<li>动态节点特征表示$e^t_v$中不仅保留了邻接节点对中心节点$v$的聚合作用，也保留了时刻$t$之前的图结构演变行为。</li>
</ul>
<h1 id="Dynamic-Self-Attention-Network"><a href="#Dynamic-Self-Attention-Network" class="headerlink" title="Dynamic Self-Attention Network"></a>Dynamic Self-Attention Network</h1><p>在本节中，首先描述模型的高层结构。DySAT主要由结构层和时序自注意层构成，它们可用于通过层的叠加构建任意的图神经网络架构，采用multi-head注意机制来提高模型容量和稳定性。</p>
<p>结构模块通过自注意聚合从局部邻域提取节点特征，计算更新每个时刻图结构的中间节点特征。这些特征作为时序模块的输入，时序块处理多个时间步骤以捕获图结构的时序变化。</p>
<p>模型结构图如下所示：</p>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1>]]></content>
      <categories>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>Graph Attention Networks</title>
    <url>/andromeda.github.io/2020/07/22/Graph-Attention-Networks/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文提出了一种新的基于图结构数据的神经网络结构，通过使用masked self-attentional layers 解决图卷积网络（GCN）的一些缺点。它允许(隐式地)为邻接结点集中的不同结点分配不同的权重，并且不需要任何昂贵的矩阵操作，比如反演，也不依赖于需要预先知道图形结构。本文同时解决了GCN的几个关键挑战，并使模型适用于归纳问题（Inductive）和（Transductive）问题。GAT模型在四个benchmark数据集（Cora、Citeseer、Pubmed和proteinprotein interaction）上取得了最佳结果。</p>
<blockquote>
<p>注：transductive 任务指：训练阶段与测试阶段都基于同样的图结构；inductive 任务指：训练阶段与测试阶段需要处理的图不同。通常训练阶段只是在子图（subgraph）上进行，测试阶段需要处理未知的顶点。（unseen nodes）</p>
</blockquote>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><p>图结构化数据</p>
<p>卷积神经网络(CNNs)已成功应用于解决图像分类、语义分割或机器翻译等问题，其中底层数据形式具有网格状结构。这种结构能够将具有可学习参数的local filter应用到所有输入位置。然而，许多有趣的任务所涉及的数据不能以网格状结构表示，而是位于一个不规则的域中，如三维网格、社交网络、电信网络、生物网络或大脑连接体。这些数据通常可以以图的形式表示。</p>
</li>
<li><p>相关前人工作</p>
<ol>
<li><p>使用递归神经网络处理用有向无环图表示的图结构数据。[1,2]</p>
</li>
<li><p>使用图神经网络[3,4]直接处理更多类型的图（如循环、有向、无向图），可看作是递归神经网络的推广。它用神经网络基于节点当前的状态来产生一个输出，不断迭代此过程来更新节点的状态，直至达到平衡。Li[5]等人采用并改进了这个想法，提出在传播步骤中使用门控循环单元[6]。</p>
</li>
</ol>
</li>
<li><p>卷积的推广</p>
<p>然而，人们对将卷积推广到图域越来越感兴趣。这方面的进展通常分为谱方法和非谱方法。</p>
</li>
</ul>
<ol>
<li><p>谱方法（基于图的谱表示）</p>
<ul>
<li><p>进展：计算图的拉普拉斯特征分解在频域里定义卷积操作；[7]</p>
<p>缺点：计算复杂，并且不具有空域局部滤波器特性。</p>
</li>
<li><p>进展：进行具有平滑系数的谱滤波器的参数化；[8]</p>
<p>缺点：计算依然复杂</p>
</li>
<li><p>进展：通过图拉普拉斯算子的切比雪夫展开式去近似滤波器，省去了特征根分解的步骤，并具有空域局部滤波器特性；[9]</p>
</li>
<li><p>进展：通过限制过滤器在每个节点周围的一步邻域内操作，简化了图卷积网络的模型；[10]</p>
</li>
</ul>
</li>
</ol>
<blockquote>
<p> 然而，在所有上述谱方法中，学习到的滤波器依赖于拉普拉斯特征基，而拉普拉斯特征基依赖于图结构。因此，针对特定结构训练的模型不能直接应用于具有不同结构的图。</p>
</blockquote>
<ol>
<li><p>非谱方法（直接在图上定义卷积，对一组空间近邻节点进行操作）</p>
<ul>
<li>挑战：如何定义一个操作能够处理不同大小的邻域，并保持CNN的权重共享性质。</li>
<li>进展：mixture model CNNs (MoNet)[11]、GraphSAGE[12]等。</li>
</ul>
</li>
</ol>
<ul>
<li><p>注意力机制</p>
<p>优势之一是它们允许处理不同大小的输入，通过关注输入中最相关的部分来做出决定。self-attention / intra-attention使用注意机制来计算单个序列的表示，不仅能提升RNN和CNN的性能，而且足以用于构建一个更强大的模型，因此本文提出了GAT，具有以下优势：</p>
<ol>
<li>操作效率高，在跨节点对中可并行计算;</li>
<li>通过对相邻节点指定任意权值，可应用于不同度的图节点;</li>
<li>该模型直接适用于归纳学习问题，包括讲模型推广到完全不可见图的任务。</li>
</ol>
</li>
</ul>
<h1 id="GAT-Architecture"><a href="#GAT-Architecture" class="headerlink" title="GAT Architecture"></a>GAT Architecture</h1><h3 id="Graph-Attentional-Layer"><a href="#Graph-Attentional-Layer" class="headerlink" title="Graph Attentional Layer"></a>Graph Attentional Layer</h3><ul>
<li><p>输入输出</p>
<p>GA层的输入是一组节点特征，记为 $\mathbf{h}=\left\{\vec{h}_{1}, \vec{h}_{2}, \ldots, \vec{h}_{N}\right\}, \vec{h}_{i} \in \mathbb{R}^{F}$ ，其中 $N$ 是节点的个数，$F$ 是每个节点的特征数。</p>
<p>GA层的输出是一组新的节点特征，记为 $\mathbf{h}^{\prime}=\left\{\vec{h}_{1}^{\prime}, \vec{h}_{2}^{\prime}, \ldots, \vec{h}_{N}^{\prime}\right\}, \vec{h}_{i}^{\prime} \in \mathbb{R}^{F^{\prime}}$，其中节点个数$N$不变，每个节点的特征数可变化为 $F^{\prime}$。</p>
</li>
<li><p>共享线性变换</p>
<p>为了将输入特征转换为高维特征（增维）以获得足够的表达能力，每个节点将经过一个共享的线性变换，该模块的参数用权重矩阵 $\mathbf{W} \in \mathbb{R}^{F^{\prime} \times F}$来表示，对某个节点做线性变换可表示为 $\mathbf{W} \vec{h}_{i} \in \mathbb{R}^{F^{\prime} }$。这是一种常见的特征增强（feature augment）方法。</p>
</li>
<li><p>self-attention 机制</p>
<p>同样是在每个节点间共享self-attention 机制：$\mathbb{R}^{F^{\prime}} \times \mathbb{R}^{F^{\prime}} \rightarrow \mathbb{R}$，可计算节点 $i$ 和 $j$ 之间的attention 系数如下：</p>
<script type="math/tex; mode=display">
e_{i j}=a\left(\mathbf{W} \vec{h}_{i}, \mathbf{W} \vec{h}_{j}\right)</script><p>该系数表示了节点 $i$ 的特征对节点 $j$ 的重要性。注意机制 $a$ 是一个单层前馈神经网络，用一个权重向量来表示：$\overrightarrow{\mathbf{a}} \in \mathbb{R}^{2 F^{\prime}}$，它把拼接后的长度为2F的高维特征映射到一个实属上，作为注意力系数。</p>
<p>attention 机制分为以下两种：</p>
<ol>
<li>Global graph attention：允许每个节点参与其他任意节点的注意力机制，它忽略了所有的图结构信息。</li>
<li><p>Masked graph attention：只允许邻接节点参与当前节点的注意力机制中，进而引入了图的结构信息。</p>
<p>本文采用Masked graph attention，并且邻接节点是一阶邻接节点（包括节点本身）。</p>
<script type="math/tex; mode=display">
\alpha_{i j}=\operatorname{softmax}_{j}\left(e_{i j}\right)=\frac{\exp \left(e_{i j}\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(e_{i k}\right)}</script><p>为了使不同节点间的注意力系数易于比较，使用softmax函数对所有对于节点 $i$ 的注意力系数进行归一化：</p>
</li>
</ol>
<p>上述注意力机制，采用共享权重线性变换、Masked self attention 和 LeakyReLU非线性（negative input slope α = 0.2）归一化后的计算公式如下，其中 T表示转置，||表示拼接：</p>
<script type="math/tex; mode=display">
\alpha_{i j}=\frac{\exp \left(\text { LeakyReLU }\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\text { Leaky ReLU }\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{k}\right]\right)\right)}</script></li>
<li><p>节点特征更新</p>
<p>在得到归一化的注意力系数之后，可以通过对邻接节点特征的线性组合经过一个非线性激活函数来更新节点自身的特征作为输出：</p>
<script type="math/tex; mode=display">
  \vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \vec{h}_{j}\right)</script><script type="math/tex; mode=display">
\vec{h}_{i}^{\prime}=\prod_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)</script></li>
</ul>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph-Attention-Networks/Snipaste_2020-07-24_11-05-51.png?raw=true" alt="Snipaste_2020-07-24_11-05-51" style="zoom:67%; float: center"></p>
<h3 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h3><p>为了稳定self-attention的学习过程，本文使用多头注意力机制。具体地，使$K$ 个独立注意力机制根据上式进行变换，得到更新的节点输出特征，然后将$K$ 个特征拼接（concat），得到如下输出特征：</p>
<script type="math/tex; mode=display">
\vec{h}_{i}^{\prime}=||_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)</script><p>如果我们在最后一层（预测层）使用Multi-head attention mechanism，需要把输出进行平均化，再使用非线性函数（softmax或logistic sigmoid），公式如下：</p>
<script type="math/tex; mode=display">
\vec{h}_{i}^{\prime}=\sigma\left(\frac{1}{K} \sum_{k=1}^{K} \sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)</script><p>Multi-head attention mechanism 的示意图如下所示：</p>
<p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph-Attention-Networks/Snipaste_2020-07-24_14-43-23.png?raw=true" alt="Snipaste_2020-07-24_14-43-23" style="zoom:80%;"></p>
<h1 id="Comparisons-to-Related-Work"><a href="#Comparisons-to-Related-Work" class="headerlink" title="Comparisons to Related Work"></a>Comparisons to Related Work</h1><p>GA层直接解决了用神经网络处理图结构数据方法中存在的几个问题：</p>
<ol>
<li>计算上高效：自注意力层的操作可以并行化到所有的边，输出特征的计算也可以并行化到所有的节点，multi-head attention 中每一头的计算也可以并行化。 </li>
<li>与GCNs不同的是，GAT模型允许(隐式地)为同一邻接节点分配不同的重要性，从而实现了模型容量的飞跃；此外，分析学习到的注意力系数可能会在可解释性方面带来一些好处。</li>
<li>注意力机制以一种共享的方式应用于图中的所有边，因此它不依赖于预先访问全局图结构或其所有节点的(特征)(这是许多先前技术的限制)。<ul>
<li>不要求图是无向的，如果 $j$ -&gt;$i$ 不存在，我们只需省去计算$\alpha_{i j}$即可。</li>
<li>使得模型能够处理inductive任务，能够在训练中完全看不到的图形上评估模型。</li>
</ul>
</li>
<li>无需对节点的重要性进行预先排序</li>
<li>GAT模型是MoNet的一个特例，但与MoNet相比，GAT模型使用节点特征进行相似性计算，而不是节点的结构属性(这需要预先知道图形结构)。</li>
</ol>
<blockquote>
<p>文章还提出了一个利用稀疏矩阵操作版本的GAT层，降低存储复杂度，并允许在更大的图数据集上执行GAT模型。但由于使用的是rank-2  tensors，它限制了GAT的批处理能力，尤其是对具有多个不同图结构的数据集来说。这也是未来的一项研究工作。  </p>
</blockquote>
<h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p><img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_15-23-08.png?raw=true" alt="Snipaste_2020-07-24_15-23-08"></p>
<ul>
<li><p>Transductive Learning：</p>
<p>Cora、Citeseer、Pubmed是三个无向固定图结构的数据集，适用于Transductive Learning。每个节点都有一个类别标签，节点特征是词向量表示。每一类用20个节点进行训练，500个节点进行验证，1000个节点进行测试。</p>
</li>
<li><p>Inductive Learning：</p>
<p>protein-protein interaction (PPI) 数据集包含不同人类组织对应的不同图结构，适用于Inductive Learning。用其中20个图进行训练，2个图进行验证，2个图进行测试。测试图在训练过程中是完全没有被观察到过的。</p>
</li>
</ul>
<h3 id="State-of-the-art-Methods"><a href="#State-of-the-art-Methods" class="headerlink" title="State-of-the-art Methods"></a>State-of-the-art Methods</h3><ul>
<li><p>Transductive Learning：</p>
<p>label propagation (LP)、semi-supervised embedding (SemiEmb)、manifold regularization (ManiReg)、skip-gram based graph embeddings (Deep- Walk)、iterative classification algorithm (ICA)、Planetoid、GCNs、graph convolutional models utilising higher-order Chebyshev filters、MoNet model</p>
</li>
<li><p>Inductive Learning：</p>
<p>GraphSAGE-GCN、GraphSAGE-mean、GraphSAGE-LSTM、GraphSAGE-pool</p>
</li>
<li><p>另外，对于这两个任务，还提供了每个节点共享多层感知器(MLP)分类器的性能(它完全不包含图结构)。</p>
</li>
</ul>
<h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><ul>
<li><p>Transductive Learning：</p>
<p>对于前两个数据集，建立两层GAT模型，第一层$K=8$, $F’=8$，输出特征数为64，经过exponential linear unit (ELU) 非线性函数；第二层用于分类，$K=1$，采用softmax激活函数。为了解决训练集较小的问题，正则化在模型中得到了广泛的应用。在训练中，我们应用L2正则化（$lamda=0.0005$），dropout（$p=0.6$）。</p>
<p>对于第三个数据集，改变第一层$K=8$，L2正则化（$lamda=0.001$），其他结构和参数保持不变。</p>
</li>
<li><p>Inductive Learning：</p>
<p>采用三层GAT模型，前两层$K=4$，$F’=256$，输出特征为1024，经过ELU 非线性函数；最后一层用于分类，$K=6$，$F’=121$，对输出特征进行平均并经过一个logistic sigmoid 激活函数。由于训练集充足，未采用L2正则化和dropout，但使用了skip connections挑过了中间的注意力层。</p>
<p>所有模型采用Glorot初始化，采用Adam SGD optimizer（Pubmed数据集学习率取0.01，其余数据集学习率为0.005），最小化交叉熵损失，使用早期停止策略。</p>
</li>
</ul>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>实验结果如下表所示：</p>
<p>​        <img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_16-42-04.png?raw=true" alt="Snipaste_2020-07-24_16-42-04"></p>
<p>​        <img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_16-42-16.png?raw=true" alt="Snipaste_2020-07-24_16-42-16"></p>
<ol>
<li>跟GCNs相比，GAT模型在Cora和Citeseer数据集上精度分别提高了1.5%和1.6%，这表明对邻接节点分配不同的注意力系数是有益的。</li>
<li>跟GraphSAGE相比，GAT在PPI数据集上精度提高了20.5%，说明了GAT模型在inductive任务上的潜力，以及对不同邻接节点分配不同注意力系数的有效性。</li>
</ol>
<p>GAT模型在Cora数据集上的分类结果可视化如下：</p>
<p>​        <img src="https://github.com/jadew0321/andromeda.github.io/blob/master/2020/07/22/Graph%20Attention%20Networks/Snipaste_2020-07-24_17-08-14.png?raw=true" alt="Snipaste_2020-07-24_17-08-14"></p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>本文提出了图注意力网络(GATs)，这是一种新型的利用masked自注意力层的卷积式神经网络，它能够处理图结构的数据，具有计算简洁、允许不同权重的邻接结点、不依赖于整个图结构等优势，可以处理谱方法的一诸多缺陷，在各数据集上获得了最佳的性能。</p>
<h1 id="Future-Works"><a href="#Future-Works" class="headerlink" title="Future Works"></a>Future Works</h1><p>有几个潜在的可改进和扩展GATs的未来工作，如克服前述只能处理一个批次数据的实际问题，使得模型能够处理更大的批次数据。另外一个特别有趣的研究方向是利用注意力机制对模型的可解释性进行深入分析。最后，扩展模型以包含边的特征(可能表示节点之间的关系)将允许我们处理更多种问题。</p>
<h1 id="Understanding"><a href="#Understanding" class="headerlink" title="Understanding"></a>Understanding</h1><ol>
<li>GAT与GCN本质思想都是将邻接节点的特征聚合到中心节点上（aggregate 运算），利用图上的local stationary 学习新的节点特征，但是两者的实现思路和方法是不同的，GCN是利用图的具体结构，构造拉普拉斯矩阵进行local convolution，而GAT是利用节点之间的相关性，构造attention系数，并且该系数只与节点的特征有关，和图的结构无关。因此GAT的学习能力会更强。</li>
<li>GAT采用逐点运算，对于有向图来说，可以根据需要选择计算节点之间的attention系数，拜托了GCN中的拉普拉斯矩阵的束缚。并且，注意力系数也仅与节点特征相关，与图结构无关，因此改变图的结构对GAT的影响不大，只需要改变邻接节点个数，重新计算即可，这也是能胜任inductive学习的原因所在。</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><blockquote>
<ol>
<li>Paolo Frasconi, Marco Gori, and Alessandro Sperduti. A general framework for adaptive processing<br>of data structures. IEEE transactions on Neural Networks, 9(5):768–786, 1998.</li>
<li>A. Sperduti and A. Starita. Supervised neural networks for the classification of structures. Trans.<br>Neur. Netw., 8(3):714–735, May 1997. ISSN 1045-9227. doi: 10.1109/72.572108.</li>
<li>Marco Gori, Gabriele Monfardini, and Franco Scarselli. A new model for learning in graph domains. In IEEE International Joint Conference on Neural Networks, pp. 729734, 2005.</li>
<li>Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini.<br>The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61–80, 2009.</li>
<li>Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural<br>networks. International Conference on Learning Representations (ICLR), 2016.</li>
<li>Kyunghyun Cho, Bart Van Merri¨enboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.</li>
<li>Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally<br>connected networks on graphs. International Conference on Learning Representations (ICLR),<br>2014.</li>
<li>Mikael Henaff, Joan Bruna, and Yann LeCun. Deep convolutional networks on graph-structured<br>data. arXiv preprint arXiv:1506.05163, 2015.</li>
<li>Micha¨el Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems, pp. 3844–3852, 2016.</li>
<li>Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. International Conference on Learning Representations (ICLR), 2017.</li>
<li>Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodol`a, Jan Svoboda, and Michael M Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. arXiv preprint arXiv:1611.08402, 2016.</li>
<li>William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large<br>graphs. Neural Information Processing Systems (NIPS), 2017.</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
</search>
